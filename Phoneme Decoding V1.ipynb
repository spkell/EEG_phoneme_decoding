{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wave\n",
    "import os\n",
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time:256Hz', 'Epoch', 'F3', 'FC5', 'AF3', 'F7', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'F8', 'AF4', 'FC6', 'F4', 'Label', 'Stage', 'Flag']\n",
      "['F3', 'FC5', 'AF3', 'F7', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'F8', 'AF4', 'FC6', 'F4']\n"
     ]
    }
   ],
   "source": [
    "labels = ['Time:256Hz','Epoch','F3','FC5','AF3','F7','T7','P7','O1','O2','P8','T8','F8','AF4','FC6','F4','Label','Stage','Flag']\n",
    "print(labels)\n",
    "channels = ['F3','FC5','AF3','F7','T7','P7','O1','O2','P8','T8','F8','AF4','FC6','F4']\n",
    "nchan = len(channels)\n",
    "print(channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FEIS Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5.0' '0' '4372.0512695313' ... '4315.6411132813' 'goose' 'stimuli']\n",
      " ['5.00390625' '0' '4366.5385742188' ... '4308.4614257813' 'goose'\n",
      "  'stimuli']\n",
      " ['5.0078125' '0' '4361.9228515625' ... '4302.9487304688' 'goose'\n",
      "  'stimuli']\n",
      " ...\n",
      " ['3523.98828125' '159' '4264.7436523438' ... '4218.3334960938' 's'\n",
      "  'resting']\n",
      " ['3523.9921875' '159' '4261.41015625' ... '4217.3076171875' 's'\n",
      "  'resting']\n",
      " ['3523.99609375' '159' '4259.615234375' ... '4215.0' 's' 'resting']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15482880"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "data = genfromtxt(\"s1_full_eeg.csv\", delimiter=',', skip_header = 1,dtype=str)\n",
    "data = np.delete(data,np.s_[-1:],axis=1)\n",
    "data_original = np.copy(data)\n",
    "print(data)\n",
    "data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Normalize data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize each channel separately\n",
    "\n",
    "data_norm = np.copy(data)\n",
    "data_norm = np.delete(data_norm,[0,1,-1,-2],1)\n",
    "data_norm = data_norm.astype(float)\n",
    "\n",
    "normed_rows = np.copy(data_norm)\n",
    "\n",
    "for chan in range(len(data_norm.T)):\n",
    "    mean = np.mean(data_norm.T[chan])\n",
    "    stdev = np.std(data_norm.T[chan])\n",
    "    for samp in range(len(data_norm.T[chan])):\n",
    "        normed_rows.T[chan][samp] = (data_norm.T[chan][samp] - mean) / stdev\n",
    "\n",
    "data_norm = normed_rows.astype(str)\n",
    "\n",
    "for chan in range(nchan):\n",
    "    data[:,chan+2] = data_norm[:,chan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures = ['resting','stimuli','thinking','speaking']\n",
    "phonemes = ['goose','thought','zh','p','sh','n','k','fleece','trap','s','ng','t','f','z','m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure data nested by task, phoneme, epoch, & sample\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: 0\n",
      "task: 1\n",
      "task: 2\n",
      "task: 3\n"
     ]
    }
   ],
   "source": [
    "#Initialize struct for each phone/procedure combo\n",
    "struct = [[],[],[],[]] #struct[procedure][phone][epoch][channel]\n",
    "for task in range(len(procedures)):\n",
    "    for phone in phonemes:\n",
    "        struct[task].append([])\n",
    "\n",
    "#Load EEG matrices into struct\n",
    "for task in range(len(procedures)):\n",
    "    for phone in range(len(phonemes)):\n",
    "        \n",
    "        epoch_ct = 0\n",
    "        epoch_index = 0\n",
    "        struct[task][phone].append([])\n",
    "        for i in range(len(data)):\n",
    "            if data[i][-2] == phonemes[phone] and data[i][-1] == procedures[task]:\n",
    "                if float(data[i][1]) > epoch_ct:\n",
    "                    struct[task][phone].append([data[i][0:16]])\n",
    "                    epoch_ct = float(data[i][1])\n",
    "                    epoch_index += 1\n",
    "                else:\n",
    "                    struct[task][phone][epoch_index].append(data[i][0:16])\n",
    "    print(\"task:\",task)\n",
    "    \n",
    "for task in range(len(procedures)):\n",
    "    for phone in range(len(phonemes)):\n",
    "        if struct[task][phone][0] == []:\n",
    "            del struct[task][phone][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Tasks\n",
      "15 Phonemes\n",
      "10 Epochs\n",
      "16 Time,nEpoch,channels\n"
     ]
    }
   ],
   "source": [
    "print(len(struct),'Tasks')\n",
    "print(len(struct[0]),'Phonemes')\n",
    "print(len(struct[0][0]),'Epochs')\n",
    "print(len(struct[0][0][0][0]),'Time,nEpoch,channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate Sound in Audio Files\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(fname):\n",
    "    input_data = read(fname)\n",
    "    audio = input_data[1]\n",
    "    plt.plot(audio[0:len(audio)])\n",
    "    #print(len(audio),\"Samples\")\n",
    "    #print(len(audio)/1000,\"Frames/ms\")\n",
    "    \n",
    "    if False:\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.title(fname)\n",
    "        plt.show()\n",
    "        \n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_sound(audio):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    start_found = False\n",
    "    for frame in range(len(audio)):\n",
    "        if audio[frame] > 100:\n",
    "            end = frame\n",
    "            if not start_found:\n",
    "                start = frame\n",
    "                start_found = True\n",
    "    \n",
    "    start_time = start/len(audio)\n",
    "    end_time = end/len(audio)\n",
    "    #print(\"Start Time:\",start_time,\"s\")\n",
    "    #print(\"End Time:\",end_time,\"s\")\n",
    "    return start_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought.wav\n",
      "k.wav\n",
      "zh.wav\n",
      "n.wav\n",
      "fleece.wav\n",
      "trap.wav\n",
      "m.wav\n",
      "z.wav\n",
      "v.wav\n",
      "t.wav\n",
      "f.wav\n",
      "p.wav\n",
      "ng.wav\n",
      "s.wav\n",
      "goose.wav\n",
      "sh.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'thought.wav': (0.1692063492063492, 0.6371428571428571),\n",
       " 'k.wav': (0.18217687074829933, 0.3958503401360544),\n",
       " 'zh.wav': (0.3193877551020408, 0.77859410430839),\n",
       " 'n.wav': (0.21634920634920635, 0.7289795918367347),\n",
       " 'fleece.wav': (0.27494331065759636, 0.6484580498866214),\n",
       " 'trap.wav': (0.1773922902494331, 0.5819501133786849),\n",
       " 'm.wav': (0.4148299319727891, 0.8319047619047619),\n",
       " 'z.wav': (0.16850340136054423, 0.6305895691609977),\n",
       " 'v.wav': (0.1045124716553288, 0.46408163265306124),\n",
       " 't.wav': (0.08229024943310657, 0.2808843537414966),\n",
       " 'f.wav': (0.13494331065759638, 0.5904761904761905),\n",
       " 'p.wav': (0.23839002267573697, 0.446530612244898),\n",
       " 'ng.wav': (0.1418140589569161, 0.844671201814059),\n",
       " 's.wav': (0.22732426303854875, 0.6972108843537415),\n",
       " 'goose.wav': (0.20997732426303856, 0.6384353741496599),\n",
       " 'sh.wav': (0.19673469387755102, 0.6691836734693878)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Determine windows within audio files when subject was sounding phoneme\n",
    "wav_time_dict = {} #Tuples to start and end times indexed by wav audio file name\n",
    "file_names = os.listdir('s1_wavs')\n",
    "for fname in file_names:\n",
    "    print(fname)\n",
    "    audio = extract_audio('s1_wavs/'+fname)\n",
    "    wav_time_dict[fname] = (isolate_sound(audio))\n",
    "\n",
    "wav_time_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map phoneme occurence from Audio to EEG\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separates all EEG samples from within the audio time window (not taking into account perception delay)\n",
    "def isolate_eeg_sounds(task, phonemes,wav_time_dict):\n",
    "    \n",
    "    n100 = 0.07 #N100 occurs 80ms after stim onset, as first indication of stimuli presentation\n",
    "    long_feats_all_phonemes = []\n",
    "    for phone in range(len(phonemes)):\n",
    "    \n",
    "        wav_start,wav_end = wav_time_dict[phonemes[phone]+'.wav'] #Start/End of phoneme in wav audio clip\n",
    "\n",
    "        long_features = [] #Contains groups of all continous sounds\n",
    "        for epoch in struct[task][phone]:\n",
    "            sound_packet = [] #1 continous sound (not whole 5 seconds of repetition)\n",
    "            init_repetition = int(float(epoch[0][0]))\n",
    "            repetition = init_repetition\n",
    "            for sample in epoch:\n",
    "\n",
    "                #Determines if EEG sample is in the audio window\n",
    "                sample_formatted = float('0.' + sample[0].split('.')[1])\n",
    "                if sample_formatted > (wav_start + n100) and sample_formatted < wav_end:\n",
    "                    if int(float(sample[0])) == repetition:\n",
    "                        sound_packet.append(sample)\n",
    "                    else:\n",
    "                        repetition = int(float(sample[0]))\n",
    "                        long_features.append(sound_packet.copy())\n",
    "                        sound_packet = []\n",
    "                        \n",
    "            long_features.append(sound_packet.copy()) #Each appended packet is a single sound\n",
    "                \n",
    "        long_feats_all_phonemes.append(long_features)\n",
    "        \n",
    "    return long_feats_all_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_feats_listen = isolate_eeg_sounds(1, phonemes) #stimuli/listening\n",
    "long_feats_think = isolate_eeg_sounds(2, phonemes) #stimuli/listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05078125\n",
      "0.05078125\n",
      "0.00390625\n"
     ]
    }
   ],
   "source": [
    "print(float(long_feats_listen[0][0][13][0]) - float(long_feats_listen[0][0][0][0])) #Window size = 13 samples\n",
    "print(float(long_feats_think[0][0][13][0]) - float(long_feats_think[0][0][0][0])) #Window size = 13 samples\n",
    "\n",
    "print(float(long_feats_listen[0][0][1][0]) - float(long_feats_listen[0][0][0][0])) #Difference over 1 time point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce sequential windows representing phoneme time series samples\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset(long_feats, phonemes, window_size=13, offset=13):\n",
    "    \n",
    "    #window_size = 13 => 0.0507 second samples = 51ms < L_phoneme\n",
    "    \n",
    "    #Construct dataset with samples of sliding window for each phoneme\n",
    "    phoneme_datasets = []\n",
    "\n",
    "    for phone in range(len(phonemes)):\n",
    "        ds = []\n",
    "        for sound_packet in long_feats[phone]:\n",
    "            ind_max = len(sound_packet)\n",
    "            start = 0\n",
    "            end = window_size\n",
    "            while ind_max > end:\n",
    "                ds.append(sound_packet[start:end])\n",
    "                start += offset\n",
    "                end += offset\n",
    "        phoneme_datasets.append(ds)\n",
    "        \n",
    "    structured_dataset = []\n",
    "    for phone_ds in phoneme_datasets:\n",
    "        temp_phone = []\n",
    "        for sound_packet in phone_ds:\n",
    "            temp_packet = []\n",
    "            for timepoint in sound_packet:\n",
    "                temp_packet.append(timepoint[2:])\n",
    "            temp_phone.append(temp_packet)\n",
    "        structured_dataset.append(np.asarray(temp_phone).astype(float))\n",
    "    \n",
    "    return structured_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "310\n",
      "13\n",
      "14\n",
      "\n",
      "15\n",
      "310\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "structured_dataset_listen = construct_dataset(long_feats_listen, phonemes)\n",
    "structured_dataset_think = construct_dataset(long_feats_think, phonemes)\n",
    "\n",
    "print(len(structured_dataset_listen)) #Number of phonemes\n",
    "print(len(structured_dataset_listen[0])) #Number of sound packets\n",
    "print(len(structured_dataset_listen[0][0])) #Number of timepoints/sound packet\n",
    "print(len(structured_dataset_listen[0][0][0])) #Number of channels\n",
    "print()\n",
    "print(len(structured_dataset_think)) #Number of phonemes\n",
    "print(len(structured_dataset_think[0])) #Number of sound packets\n",
    "print(len(structured_dataset_think[0][0])) #Number of timepoints/sound packet\n",
    "print(len(structured_dataset_think[0][0][0])) #Number of channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training/validation datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x,t,training_size=0.8): #x=phoneme[i], t=target phoneme label\n",
    "\n",
    "    #Identifies indices to split data by\n",
    "    data_index = np.arange(len(t))\n",
    "    random.shuffle(data_index)\n",
    "    training_index = data_index[:int(training_size*len(t))]\n",
    "    testing_index = data_index[int(training_size*len(t)):]\n",
    "\n",
    "    training_x = []\n",
    "    training_t = []\n",
    "    for index in training_index:\n",
    "        training_x.append(x[index])\n",
    "        training_t.append(t[index])\n",
    "\n",
    "    testing_x = []\n",
    "    testing_t = []\n",
    "    for index in testing_index:\n",
    "        testing_x.append(x[index])\n",
    "        testing_t.append(t[index])\n",
    "        \n",
    "    training_x = np.asarray(training_x)\n",
    "    training_t = np.asarray(training_t)\n",
    "    testing_x = np.asarray(testing_x)\n",
    "    testing_t = np.asarray(testing_t)\n",
    "    \n",
    "    return training_x,training_t,testing_x,testing_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4560\n",
      "4560\n",
      "training_x: 3648\n",
      "testing_x: 912\n",
      "training_t: 3648\n",
      "testing_t: 912\n"
     ]
    }
   ],
   "source": [
    "#Stack all samples into single matrix\n",
    "x = [] #datapoints\n",
    "t = [] #labels\n",
    "for phone in range(len(structured_dataset_listen)):\n",
    "    for sound_packet in structured_dataset_listen[phone]:\n",
    "        x.append(sound_packet)\n",
    "        t.append(phone)\n",
    "\n",
    "print(len(x))\n",
    "print(len(t))\n",
    "\n",
    "training_x,training_t,testing_x,testing_t = split_data(x,t)\n",
    "\n",
    "print(\"training_x:\",len(training_x))\n",
    "print(\"testing_x:\",len(testing_x))\n",
    "print(\"training_t:\",len(training_t))\n",
    "print(\"testing_t:\",len(testing_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Model - Train&Test on stim/audio EEG\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 14)\n",
      "(3648, 13, 14)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (training_x.shape[1:])\n",
    "print(input_shape)\n",
    "print(training_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_19 (Flatten)         (None, 182)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1000)              183000    \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 15)                15015     \n",
      "=================================================================\n",
      "Total params: 9,207,015\n",
      "Trainable params: 9,207,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(input_shape)),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(15, activation=tf.keras.activations.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tf.keras.backend.set_value(model.optimizer.learning_rate, 0.000005)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "114/114 [==============================] - 5s 36ms/step - loss: 2.7060 - accuracy: 0.0778\n",
      "Epoch 2/100\n",
      "114/114 [==============================] - 4s 34ms/step - loss: 2.6569 - accuracy: 0.1333\n",
      "Epoch 3/100\n",
      "114/114 [==============================] - 4s 38ms/step - loss: 2.5955 - accuracy: 0.1410\n",
      "Epoch 4/100\n",
      "114/114 [==============================] - 4s 37ms/step - loss: 2.5767 - accuracy: 0.1276\n",
      "Epoch 5/100\n",
      "114/114 [==============================] - 5s 42ms/step - loss: 2.5475 - accuracy: 0.1432\n",
      "Epoch 6/100\n",
      "114/114 [==============================] - 4s 36ms/step - loss: 2.5137 - accuracy: 0.1725\n",
      "Epoch 7/100\n",
      "114/114 [==============================] - 4s 35ms/step - loss: 2.4545 - accuracy: 0.2216\n",
      "Epoch 8/100\n",
      "114/114 [==============================] - 4s 33ms/step - loss: 2.4055 - accuracy: 0.2349\n",
      "Epoch 9/100\n",
      "114/114 [==============================] - 4s 35ms/step - loss: 2.3419 - accuracy: 0.2575\n",
      "Epoch 10/100\n",
      "114/114 [==============================] - 4s 33ms/step - loss: 2.2659 - accuracy: 0.2886\n",
      "Epoch 11/100\n",
      "114/114 [==============================] - 4s 34ms/step - loss: 2.1915 - accuracy: 0.3136\n",
      "Epoch 12/100\n",
      "114/114 [==============================] - 4s 34ms/step - loss: 2.1167 - accuracy: 0.3645\n",
      "Epoch 13/100\n",
      "114/114 [==============================] - 4s 33ms/step - loss: 2.0501 - accuracy: 0.3816\n",
      "Epoch 14/100\n",
      "114/114 [==============================] - 4s 35ms/step - loss: 1.9469 - accuracy: 0.4126\n",
      "Epoch 15/100\n",
      "114/114 [==============================] - 4s 35ms/step - loss: 1.8657 - accuracy: 0.4374\n",
      "Epoch 16/100\n",
      "114/114 [==============================] - 4s 35ms/step - loss: 1.7851 - accuracy: 0.4630\n",
      "Epoch 17/100\n",
      "114/114 [==============================] - 4s 34ms/step - loss: 1.7426 - accuracy: 0.4689\n",
      "Epoch 18/100\n",
      "114/114 [==============================] - 4s 36ms/step - loss: 1.6624 - accuracy: 0.5105\n",
      "Epoch 19/100\n",
      "114/114 [==============================] - 4s 36ms/step - loss: 1.5775 - accuracy: 0.5349\n",
      "Epoch 20/100\n",
      "114/114 [==============================] - 4s 36ms/step - loss: 1.5586 - accuracy: 0.5327\n",
      "Epoch 21/100\n",
      "114/114 [==============================] - 4s 34ms/step - loss: 1.5127 - accuracy: 0.5594\n",
      "Epoch 22/100\n",
      "114/114 [==============================] - 6s 54ms/step - loss: 1.4510 - accuracy: 0.5597\n",
      "Epoch 23/100\n",
      "114/114 [==============================] - 5s 42ms/step - loss: 1.3359 - accuracy: 0.6282\n",
      "Epoch 24/100\n",
      "114/114 [==============================] - 4s 36ms/step - loss: 1.3034 - accuracy: 0.6287\n",
      "Epoch 25/100\n",
      "114/114 [==============================] - 5s 40ms/step - loss: 1.2110 - accuracy: 0.6701\n",
      "Epoch 26/100\n",
      "114/114 [==============================] - 5s 40ms/step - loss: 1.1733 - accuracy: 0.6720\n",
      "Epoch 27/100\n",
      "114/114 [==============================] - 5s 44ms/step - loss: 1.1395 - accuracy: 0.6783\n",
      "Epoch 28/100\n",
      "114/114 [==============================] - 5s 42ms/step - loss: 1.0859 - accuracy: 0.6982\n",
      "Epoch 29/100\n",
      "114/114 [==============================] - 6s 52ms/step - loss: 1.0340 - accuracy: 0.7062\n",
      "Epoch 30/100\n",
      "114/114 [==============================] - 5s 44ms/step - loss: 0.9995 - accuracy: 0.7180\n",
      "Epoch 31/100\n",
      "114/114 [==============================] - 4s 36ms/step - loss: 0.9182 - accuracy: 0.7537\n",
      "Epoch 32/100\n",
      "114/114 [==============================] - 8s 69ms/step - loss: 0.9080 - accuracy: 0.7582\n",
      "Epoch 33/100\n",
      "114/114 [==============================] - 6s 54ms/step - loss: 0.8716 - accuracy: 0.7642\n",
      "Epoch 34/100\n",
      "114/114 [==============================] - 5s 41ms/step - loss: 0.7934 - accuracy: 0.7899\n",
      "Epoch 35/100\n",
      "114/114 [==============================] - 6s 51ms/step - loss: 0.7948 - accuracy: 0.7894\n",
      "Epoch 36/100\n",
      "114/114 [==============================] - 5s 45ms/step - loss: 0.7371 - accuracy: 0.8103\n",
      "Epoch 37/100\n",
      "114/114 [==============================] - 6s 48ms/step - loss: 0.6981 - accuracy: 0.8230\n",
      "Epoch 38/100\n",
      "114/114 [==============================] - 6s 56ms/step - loss: 0.6746 - accuracy: 0.8206\n",
      "Epoch 39/100\n",
      "114/114 [==============================] - 7s 57ms/step - loss: 0.6340 - accuracy: 0.8443\n",
      "Epoch 40/100\n",
      "114/114 [==============================] - 4s 38ms/step - loss: 0.5968 - accuracy: 0.8530\n",
      "Epoch 41/100\n",
      "114/114 [==============================] - 4s 37ms/step - loss: 0.5598 - accuracy: 0.8690\n",
      "Epoch 42/100\n",
      "114/114 [==============================] - 5s 41ms/step - loss: 0.5113 - accuracy: 0.8865\n",
      "Epoch 43/100\n",
      "114/114 [==============================] - 4s 38ms/step - loss: 0.5182 - accuracy: 0.8846\n",
      "Epoch 44/100\n",
      "114/114 [==============================] - 4s 39ms/step - loss: 0.4834 - accuracy: 0.8946\n",
      "Epoch 45/100\n",
      "114/114 [==============================] - 4s 39ms/step - loss: 0.4439 - accuracy: 0.9059\n",
      "Epoch 46/100\n",
      "114/114 [==============================] - 5s 43ms/step - loss: 0.4110 - accuracy: 0.9162\n",
      "Epoch 47/100\n",
      "114/114 [==============================] - 6s 53ms/step - loss: 0.4001 - accuracy: 0.9160\n",
      "Epoch 48/100\n",
      " 94/114 [=======================>......] - ETA: 1s - loss: 0.3783 - accuracy: 0.9183"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-439cd814acca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(training_x, training_t, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd2e3fb7690>]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 - 1s - loss: 2.7088 - accuracy: 0.0359\n",
      "Train accuracy: 0.03591008856892586\n",
      "\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 2.7090 - accuracy: 0.0362\n",
      "Test accuracy: 0.03618421033024788\n"
     ]
    }
   ],
   "source": [
    "def eval_model(training_x,training_t,testing_x,testing_t):\n",
    "\n",
    "    train_loss, train_acc = model.evaluate(training_x,  training_t, verbose=2)\n",
    "    print('Train accuracy:', train_acc)\n",
    "    print()\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(testing_x,  testing_t, verbose=2)\n",
    "    print('Test accuracy:', test_acc)\n",
    "\n",
    "eval_model(training_x,training_t,testing_x,testing_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "chance = 1/len(phonemes)\n",
    "print(chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(testing_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gramian Angular Field Pre-process for CNN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Transform dataset to Gramian Angular Field to project time series to matrix using polar coordinates\n",
    "#https://pyts.readthedocs.io/en/stable/generated/pyts.image.GramianAngularField.html\n",
    "#https://medium.com/analytics-vidhya/encoding-time-series-as-images-b043becbdbf3\n",
    "from pyts.image import GramianAngularField\n",
    "\n",
    "def to_gaf(x_partition):\n",
    "    \n",
    "    x_part_gaf = []\n",
    "    transformer = GramianAngularField()\n",
    "    for x in x_partition:\n",
    "        x_part_gaf.append(transformer.transform(x).T)\n",
    "        \n",
    "    x_part_gaf = np.asarray(x_part_gaf)\n",
    "\n",
    "    return x_part_gaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 14, 26) \n",
      "\n",
      "(1680, 14, 14, 26)\n",
      "(1680, 26, 14)\n",
      "(420, 14, 14, 26)\n",
      "(420, 26, 14)\n"
     ]
    }
   ],
   "source": [
    "training_x_gaf = to_gaf(training_x)\n",
    "testing_x_gaf = to_gaf(testing_x)\n",
    "\n",
    "input_size_gaf = training_x_gaf.shape[1:]\n",
    "print(input_size_gaf,'\\n')\n",
    "print(training_x_gaf.shape)\n",
    "print(training_x.shape)\n",
    "\n",
    "print(testing_x_gaf.shape)\n",
    "print(testing_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 14)        378       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 14)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 28)          1596      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 28)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 28)          3164      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 28)                3164      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 15)                435       \n",
      "=================================================================\n",
      "Total params: 8,737\n",
      "Trainable params: 8,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(input_size_gaf[0], 1, padding=\"same\", activation='relu', input_shape=input_size_gaf))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(input_size_gaf[0]*2, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(input_size_gaf[0]*2, (2, 2), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(input_size_gaf[0]*2, activation='relu'))\n",
    "model.add(layers.Dense(15))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tf.keras.backend.set_value(model.optimizer.learning_rate, 0.000025)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "53/53 [==============================] - 1s 4ms/step - loss: 8.4675 - accuracy: 0.0714\n",
      "Epoch 2/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.0678 - accuracy: 0.0773\n",
      "Epoch 3/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.1108 - accuracy: 0.0790\n",
      "Epoch 4/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.9683 - accuracy: 0.0818\n",
      "Epoch 5/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.8676 - accuracy: 0.0740\n",
      "Epoch 6/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.7766 - accuracy: 0.0756\n",
      "Epoch 7/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5708 - accuracy: 0.0742\n",
      "Epoch 8/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.6340 - accuracy: 0.0686\n",
      "Epoch 9/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3926 - accuracy: 0.0931\n",
      "Epoch 10/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5742 - accuracy: 0.0685\n",
      "Epoch 11/500\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 7.3562 - accuracy: 0.0792\n",
      "Epoch 12/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.4379 - accuracy: 0.0699\n",
      "Epoch 13/500\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.6251 - accuracy: 0.0683\n",
      "Epoch 14/500\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 7.3026 - accuracy: 0.0655\n",
      "Epoch 15/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.6507 - accuracy: 0.0597\n",
      "Epoch 16/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.2538 - accuracy: 0.0613\n",
      "Epoch 17/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.7228 - accuracy: 0.0651\n",
      "Epoch 18/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.6728 - accuracy: 0.0695\n",
      "Epoch 19/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.3797 - accuracy: 0.0798\n",
      "Epoch 20/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.2717 - accuracy: 0.0859\n",
      "Epoch 21/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 7.5634 - accuracy: 0.0851\n",
      "Epoch 22/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4810 - accuracy: 0.0723\n",
      "Epoch 23/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3658 - accuracy: 0.0785\n",
      "Epoch 24/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5890 - accuracy: 0.0830\n",
      "Epoch 25/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0970 - accuracy: 0.0881\n",
      "Epoch 26/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1975 - accuracy: 0.0940\n",
      "Epoch 27/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2068 - accuracy: 0.0944\n",
      "Epoch 28/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0907 - accuracy: 0.0978\n",
      "Epoch 29/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.4813 - accuracy: 0.0878\n",
      "Epoch 30/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2803 - accuracy: 0.0914\n",
      "Epoch 31/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3667 - accuracy: 0.0939\n",
      "Epoch 32/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2081 - accuracy: 0.0943\n",
      "Epoch 33/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2915 - accuracy: 0.1000\n",
      "Epoch 34/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0050 - accuracy: 0.1089\n",
      "Epoch 35/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2391 - accuracy: 0.1015\n",
      "Epoch 36/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0642 - accuracy: 0.1071\n",
      "Epoch 37/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4336 - accuracy: 0.1213\n",
      "Epoch 38/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.6434 - accuracy: 0.1059\n",
      "Epoch 39/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3062 - accuracy: 0.1107\n",
      "Epoch 40/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2847 - accuracy: 0.1360\n",
      "Epoch 41/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3430 - accuracy: 0.1089\n",
      "Epoch 42/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3725 - accuracy: 0.1101\n",
      "Epoch 43/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0460 - accuracy: 0.1191\n",
      "Epoch 44/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 7.7682 - accuracy: 0.1042\n",
      "Epoch 45/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2641 - accuracy: 0.1173\n",
      "Epoch 46/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0373 - accuracy: 0.1186\n",
      "Epoch 47/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2487 - accuracy: 0.1148\n",
      "Epoch 48/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1409 - accuracy: 0.1132\n",
      "Epoch 49/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2791 - accuracy: 0.1062\n",
      "Epoch 50/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1172 - accuracy: 0.1048\n",
      "Epoch 51/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0504 - accuracy: 0.1133\n",
      "Epoch 52/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2379 - accuracy: 0.1160\n",
      "Epoch 53/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2946 - accuracy: 0.1028\n",
      "Epoch 54/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1546 - accuracy: 0.0902\n",
      "Epoch 55/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2835 - accuracy: 0.1259\n",
      "Epoch 56/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2463 - accuracy: 0.1044\n",
      "Epoch 57/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4317 - accuracy: 0.0947\n",
      "Epoch 58/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.0393 - accuracy: 0.0960\n",
      "Epoch 59/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0594 - accuracy: 0.1131\n",
      "Epoch 60/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3091 - accuracy: 0.1103\n",
      "Epoch 61/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5793 - accuracy: 0.1038\n",
      "Epoch 62/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0010 - accuracy: 0.0989\n",
      "Epoch 63/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1335 - accuracy: 0.1121\n",
      "Epoch 64/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1109 - accuracy: 0.0992\n",
      "Epoch 65/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0756 - accuracy: 0.0954\n",
      "Epoch 66/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.3240 - accuracy: 0.1068\n",
      "Epoch 67/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.3200 - accuracy: 0.1006\n",
      "Epoch 68/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1868 - accuracy: 0.1058\n",
      "Epoch 69/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9625 - accuracy: 0.1100\n",
      "Epoch 70/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9801 - accuracy: 0.1034\n",
      "Epoch 71/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2213 - accuracy: 0.1040\n",
      "Epoch 72/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2724 - accuracy: 0.1111\n",
      "Epoch 73/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0784 - accuracy: 0.1047\n",
      "Epoch 74/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2890 - accuracy: 0.1185\n",
      "Epoch 75/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2454 - accuracy: 0.1114\n",
      "Epoch 76/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.5962 - accuracy: 0.1168\n",
      "Epoch 77/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1552 - accuracy: 0.1056\n",
      "Epoch 78/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2453 - accuracy: 0.1067\n",
      "Epoch 79/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3432 - accuracy: 0.1088\n",
      "Epoch 80/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8633 - accuracy: 0.1145\n",
      "Epoch 81/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3515 - accuracy: 0.1036\n",
      "Epoch 82/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1060 - accuracy: 0.1194\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 7.5640 - accuracy: 0.1085\n",
      "Epoch 84/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0733 - accuracy: 0.1302\n",
      "Epoch 85/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8842 - accuracy: 0.1160\n",
      "Epoch 86/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0650 - accuracy: 0.1072\n",
      "Epoch 87/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2596 - accuracy: 0.1152\n",
      "Epoch 88/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.1016 - accuracy: 0.1047\n",
      "Epoch 89/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9466 - accuracy: 0.1152\n",
      "Epoch 90/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7222 - accuracy: 0.1051\n",
      "Epoch 91/500\n",
      "53/53 [==============================] - ETA: 0s - loss: 7.1044 - accuracy: 0.11 - 0s 3ms/step - loss: 7.1043 - accuracy: 0.1152\n",
      "Epoch 92/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0718 - accuracy: 0.1142\n",
      "Epoch 93/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1086 - accuracy: 0.1098\n",
      "Epoch 94/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1166 - accuracy: 0.1050\n",
      "Epoch 95/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9749 - accuracy: 0.1078\n",
      "Epoch 96/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.2291 - accuracy: 0.1144\n",
      "Epoch 97/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2015 - accuracy: 0.1195\n",
      "Epoch 98/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.1098 - accuracy: 0.1108\n",
      "Epoch 99/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0029 - accuracy: 0.1181\n",
      "Epoch 100/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2665 - accuracy: 0.1084\n",
      "Epoch 101/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2233 - accuracy: 0.1101\n",
      "Epoch 102/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9658 - accuracy: 0.1012\n",
      "Epoch 103/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.1268 - accuracy: 0.1215\n",
      "Epoch 104/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7843 - accuracy: 0.1095\n",
      "Epoch 105/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2279 - accuracy: 0.1080\n",
      "Epoch 106/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7336 - accuracy: 0.1165\n",
      "Epoch 107/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9438 - accuracy: 0.1071\n",
      "Epoch 108/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2305 - accuracy: 0.1062\n",
      "Epoch 109/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.1294 - accuracy: 0.1067\n",
      "Epoch 110/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0144 - accuracy: 0.1185\n",
      "Epoch 111/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8494 - accuracy: 0.1145\n",
      "Epoch 112/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8801 - accuracy: 0.1159\n",
      "Epoch 113/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9032 - accuracy: 0.1232\n",
      "Epoch 114/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0105 - accuracy: 0.1111\n",
      "Epoch 115/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7755 - accuracy: 0.1173\n",
      "Epoch 116/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9423 - accuracy: 0.1214\n",
      "Epoch 117/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8814 - accuracy: 0.1098\n",
      "Epoch 118/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.1444 - accuracy: 0.1131\n",
      "Epoch 119/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1530 - accuracy: 0.1129\n",
      "Epoch 120/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9314 - accuracy: 0.1196\n",
      "Epoch 121/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0176 - accuracy: 0.1263\n",
      "Epoch 122/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0720 - accuracy: 0.1092\n",
      "Epoch 123/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6934 - accuracy: 0.1016\n",
      "Epoch 124/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9824 - accuracy: 0.1154\n",
      "Epoch 125/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9509 - accuracy: 0.1206\n",
      "Epoch 126/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8904 - accuracy: 0.1231\n",
      "Epoch 127/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.2534 - accuracy: 0.1076\n",
      "Epoch 128/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9227 - accuracy: 0.1159\n",
      "Epoch 129/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0289 - accuracy: 0.1082\n",
      "Epoch 130/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0797 - accuracy: 0.1042\n",
      "Epoch 131/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8398 - accuracy: 0.1177\n",
      "Epoch 132/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7135 - accuracy: 0.1212\n",
      "Epoch 133/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0325 - accuracy: 0.1147\n",
      "Epoch 134/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9721 - accuracy: 0.1086\n",
      "Epoch 135/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8090 - accuracy: 0.1257\n",
      "Epoch 136/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0145 - accuracy: 0.1189\n",
      "Epoch 137/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9663 - accuracy: 0.1133\n",
      "Epoch 138/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7290 - accuracy: 0.1053\n",
      "Epoch 139/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9980 - accuracy: 0.1197\n",
      "Epoch 140/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9963 - accuracy: 0.1032\n",
      "Epoch 141/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9146 - accuracy: 0.1244\n",
      "Epoch 142/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9860 - accuracy: 0.1110\n",
      "Epoch 143/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0099 - accuracy: 0.1146\n",
      "Epoch 144/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7626 - accuracy: 0.1157\n",
      "Epoch 145/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8912 - accuracy: 0.1263\n",
      "Epoch 146/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6298 - accuracy: 0.1248\n",
      "Epoch 147/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9217 - accuracy: 0.1122\n",
      "Epoch 148/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1195 - accuracy: 0.1122\n",
      "Epoch 149/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9338 - accuracy: 0.1111\n",
      "Epoch 150/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9082 - accuracy: 0.1200\n",
      "Epoch 151/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9911 - accuracy: 0.1068\n",
      "Epoch 152/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6129 - accuracy: 0.1259\n",
      "Epoch 153/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0246 - accuracy: 0.1256\n",
      "Epoch 154/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8043 - accuracy: 0.1171\n",
      "Epoch 155/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6391 - accuracy: 0.1224\n",
      "Epoch 156/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8954 - accuracy: 0.1191\n",
      "Epoch 157/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6720 - accuracy: 0.1195\n",
      "Epoch 158/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8342 - accuracy: 0.1123\n",
      "Epoch 159/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7067 - accuracy: 0.1295\n",
      "Epoch 160/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8520 - accuracy: 0.1356\n",
      "Epoch 161/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6171 - accuracy: 0.1380\n",
      "Epoch 162/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9895 - accuracy: 0.1259\n",
      "Epoch 163/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9277 - accuracy: 0.1272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9505 - accuracy: 0.1272\n",
      "Epoch 165/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.4647 - accuracy: 0.1424\n",
      "Epoch 166/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5322 - accuracy: 0.1323\n",
      "Epoch 167/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9030 - accuracy: 0.1238\n",
      "Epoch 168/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5157 - accuracy: 0.1513\n",
      "Epoch 169/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6234 - accuracy: 0.1360\n",
      "Epoch 170/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9391 - accuracy: 0.1294\n",
      "Epoch 171/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7938 - accuracy: 0.1310\n",
      "Epoch 172/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 7.0545 - accuracy: 0.1105\n",
      "Epoch 173/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8476 - accuracy: 0.1356\n",
      "Epoch 174/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8756 - accuracy: 0.1381\n",
      "Epoch 175/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8164 - accuracy: 0.1342\n",
      "Epoch 176/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8682 - accuracy: 0.1297\n",
      "Epoch 177/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8070 - accuracy: 0.1226\n",
      "Epoch 178/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6008 - accuracy: 0.1291\n",
      "Epoch 179/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6952 - accuracy: 0.1347\n",
      "Epoch 180/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7580 - accuracy: 0.1293\n",
      "Epoch 181/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5448 - accuracy: 0.1395\n",
      "Epoch 182/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7807 - accuracy: 0.1329\n",
      "Epoch 183/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3956 - accuracy: 0.1395\n",
      "Epoch 184/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.4734 - accuracy: 0.1281\n",
      "Epoch 185/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7531 - accuracy: 0.1144\n",
      "Epoch 186/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6386 - accuracy: 0.1280\n",
      "Epoch 187/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.6502 - accuracy: 0.1267\n",
      "Epoch 188/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5221 - accuracy: 0.1366\n",
      "Epoch 189/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5547 - accuracy: 0.1323\n",
      "Epoch 190/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.8195 - accuracy: 0.1233\n",
      "Epoch 191/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8616 - accuracy: 0.1331\n",
      "Epoch 192/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9080 - accuracy: 0.1318\n",
      "Epoch 193/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7357 - accuracy: 0.1341\n",
      "Epoch 194/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6465 - accuracy: 0.1300\n",
      "Epoch 195/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5503 - accuracy: 0.1373\n",
      "Epoch 196/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.4965 - accuracy: 0.1430\n",
      "Epoch 197/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5181 - accuracy: 0.1254\n",
      "Epoch 198/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3647 - accuracy: 0.1490\n",
      "Epoch 199/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9272 - accuracy: 0.1329\n",
      "Epoch 200/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.9885 - accuracy: 0.1385\n",
      "Epoch 201/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9056 - accuracy: 0.1298\n",
      "Epoch 202/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.9939 - accuracy: 0.1226\n",
      "Epoch 203/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7324 - accuracy: 0.1228\n",
      "Epoch 204/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7172 - accuracy: 0.1365\n",
      "Epoch 205/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6896 - accuracy: 0.1393\n",
      "Epoch 206/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6247 - accuracy: 0.1268\n",
      "Epoch 207/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4412 - accuracy: 0.1326\n",
      "Epoch 208/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5829 - accuracy: 0.1298\n",
      "Epoch 209/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5689 - accuracy: 0.1367\n",
      "Epoch 210/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4619 - accuracy: 0.1363\n",
      "Epoch 211/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5994 - accuracy: 0.1381\n",
      "Epoch 212/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5496 - accuracy: 0.1381\n",
      "Epoch 213/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3994 - accuracy: 0.1338\n",
      "Epoch 214/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5284 - accuracy: 0.1367\n",
      "Epoch 215/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.5988 - accuracy: 0.1330\n",
      "Epoch 216/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.7793 - accuracy: 0.1237\n",
      "Epoch 217/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.4862 - accuracy: 0.1291\n",
      "Epoch 218/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.4166 - accuracy: 0.1495\n",
      "Epoch 219/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7343 - accuracy: 0.1374\n",
      "Epoch 220/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5692 - accuracy: 0.1342\n",
      "Epoch 221/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6424 - accuracy: 0.1390\n",
      "Epoch 222/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4833 - accuracy: 0.1358\n",
      "Epoch 223/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5708 - accuracy: 0.1502\n",
      "Epoch 224/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4924 - accuracy: 0.1306\n",
      "Epoch 225/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4989 - accuracy: 0.1366\n",
      "Epoch 226/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3021 - accuracy: 0.1403\n",
      "Epoch 227/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6562 - accuracy: 0.1473\n",
      "Epoch 228/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4987 - accuracy: 0.1523\n",
      "Epoch 229/500\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.2540 - accuracy: 0.1421\n",
      "Epoch 230/500\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.5428 - accuracy: 0.1457\n",
      "Epoch 231/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.5786 - accuracy: 0.1454\n",
      "Epoch 232/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.4289 - accuracy: 0.1485\n",
      "Epoch 233/500\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 6.4989 - accuracy: 0.1459\n",
      "Epoch 234/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.8032 - accuracy: 0.1465\n",
      "Epoch 235/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.6076 - accuracy: 0.1370\n",
      "Epoch 236/500\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 6.3007 - accuracy: 0.1426\n",
      "Epoch 237/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.5189 - accuracy: 0.1315\n",
      "Epoch 238/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5766 - accuracy: 0.1417\n",
      "Epoch 239/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.4086 - accuracy: 0.1355\n",
      "Epoch 240/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.5463 - accuracy: 0.1254\n",
      "Epoch 241/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6379 - accuracy: 0.1365\n",
      "Epoch 242/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5161 - accuracy: 0.1254\n",
      "Epoch 243/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5179 - accuracy: 0.1362\n",
      "Epoch 244/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4304 - accuracy: 0.1353\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 8ms/step - loss: 6.5065 - accuracy: 0.1269\n",
      "Epoch 246/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5819 - accuracy: 0.1410\n",
      "Epoch 247/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4270 - accuracy: 0.1378\n",
      "Epoch 248/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3758 - accuracy: 0.1595\n",
      "Epoch 249/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4911 - accuracy: 0.1519\n",
      "Epoch 250/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2781 - accuracy: 0.1411\n",
      "Epoch 251/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6568 - accuracy: 0.1300\n",
      "Epoch 252/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2759 - accuracy: 0.1370\n",
      "Epoch 253/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3076 - accuracy: 0.1461\n",
      "Epoch 254/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6254 - accuracy: 0.1292\n",
      "Epoch 255/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5744 - accuracy: 0.1293\n",
      "Epoch 256/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5647 - accuracy: 0.1268\n",
      "Epoch 257/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3308 - accuracy: 0.1419\n",
      "Epoch 258/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3901 - accuracy: 0.1607\n",
      "Epoch 259/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4949 - accuracy: 0.1414\n",
      "Epoch 260/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5674 - accuracy: 0.1395\n",
      "Epoch 261/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3972 - accuracy: 0.1515\n",
      "Epoch 262/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.8858 - accuracy: 0.1389\n",
      "Epoch 263/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5645 - accuracy: 0.1535\n",
      "Epoch 264/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4783 - accuracy: 0.1408\n",
      "Epoch 265/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7480 - accuracy: 0.1376\n",
      "Epoch 266/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6262 - accuracy: 0.1471\n",
      "Epoch 267/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4051 - accuracy: 0.1410\n",
      "Epoch 268/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5234 - accuracy: 0.1392\n",
      "Epoch 269/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.3054 - accuracy: 0.1475\n",
      "Epoch 270/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4521 - accuracy: 0.1455\n",
      "Epoch 271/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5897 - accuracy: 0.1457\n",
      "Epoch 272/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.2544 - accuracy: 0.1413\n",
      "Epoch 273/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6156 - accuracy: 0.1382\n",
      "Epoch 274/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5546 - accuracy: 0.1378\n",
      "Epoch 275/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3224 - accuracy: 0.1402\n",
      "Epoch 276/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3908 - accuracy: 0.1472\n",
      "Epoch 277/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3858 - accuracy: 0.1400\n",
      "Epoch 278/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5723 - accuracy: 0.1250\n",
      "Epoch 279/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3197 - accuracy: 0.1611\n",
      "Epoch 280/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4598 - accuracy: 0.1444\n",
      "Epoch 281/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2345 - accuracy: 0.1514\n",
      "Epoch 282/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6654 - accuracy: 0.1222\n",
      "Epoch 283/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4397 - accuracy: 0.1382\n",
      "Epoch 284/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.1841 - accuracy: 0.1384\n",
      "Epoch 285/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.1610 - accuracy: 0.1621\n",
      "Epoch 286/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3065 - accuracy: 0.1351\n",
      "Epoch 287/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3650 - accuracy: 0.1518\n",
      "Epoch 288/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1870 - accuracy: 0.1424\n",
      "Epoch 289/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4620 - accuracy: 0.1430\n",
      "Epoch 290/500\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 6.3220 - accuracy: 0.1584\n",
      "Epoch 291/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9979 - accuracy: 0.1533\n",
      "Epoch 292/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4566 - accuracy: 0.1428\n",
      "Epoch 293/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3074 - accuracy: 0.1516\n",
      "Epoch 294/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0529 - accuracy: 0.1413\n",
      "Epoch 295/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2833 - accuracy: 0.1610\n",
      "Epoch 296/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3294 - accuracy: 0.1474\n",
      "Epoch 297/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2211 - accuracy: 0.1527\n",
      "Epoch 298/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3870 - accuracy: 0.1381\n",
      "Epoch 299/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4454 - accuracy: 0.1531\n",
      "Epoch 300/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5064 - accuracy: 0.1398\n",
      "Epoch 301/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4961 - accuracy: 0.1448\n",
      "Epoch 302/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2991 - accuracy: 0.1501\n",
      "Epoch 303/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3640 - accuracy: 0.1306\n",
      "Epoch 304/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1701 - accuracy: 0.1362\n",
      "Epoch 305/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2719 - accuracy: 0.1598\n",
      "Epoch 306/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3392 - accuracy: 0.1426\n",
      "Epoch 307/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4785 - accuracy: 0.1402\n",
      "Epoch 308/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1783 - accuracy: 0.1528\n",
      "Epoch 309/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0367 - accuracy: 0.1500\n",
      "Epoch 310/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0044 - accuracy: 0.1527\n",
      "Epoch 311/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3783 - accuracy: 0.1445\n",
      "Epoch 312/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2639 - accuracy: 0.1452\n",
      "Epoch 313/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3844 - accuracy: 0.1457\n",
      "Epoch 314/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3658 - accuracy: 0.1441\n",
      "Epoch 315/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1669 - accuracy: 0.1502\n",
      "Epoch 316/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3098 - accuracy: 0.1458\n",
      "Epoch 317/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1549 - accuracy: 0.1610\n",
      "Epoch 318/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3321 - accuracy: 0.1536\n",
      "Epoch 319/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9756 - accuracy: 0.1523\n",
      "Epoch 320/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5454 - accuracy: 0.1407\n",
      "Epoch 321/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5183 - accuracy: 0.1395\n",
      "Epoch 322/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4274 - accuracy: 0.1484\n",
      "Epoch 323/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1556 - accuracy: 0.1621\n",
      "Epoch 324/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0322 - accuracy: 0.1523\n",
      "Epoch 325/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3184 - accuracy: 0.1483\n",
      "Epoch 326/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3587 - accuracy: 0.1508\n",
      "Epoch 327/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4430 - accuracy: 0.1416\n",
      "Epoch 328/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3272 - accuracy: 0.1270\n",
      "Epoch 329/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3515 - accuracy: 0.1426\n",
      "Epoch 330/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1682 - accuracy: 0.1539\n",
      "Epoch 331/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6223 - accuracy: 0.1300\n",
      "Epoch 332/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2839 - accuracy: 0.1513\n",
      "Epoch 333/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2743 - accuracy: 0.1515\n",
      "Epoch 334/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0159 - accuracy: 0.1449\n",
      "Epoch 335/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0452 - accuracy: 0.1416\n",
      "Epoch 336/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1690 - accuracy: 0.1503\n",
      "Epoch 337/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3159 - accuracy: 0.1468\n",
      "Epoch 338/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2140 - accuracy: 0.1512\n",
      "Epoch 339/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.9984 - accuracy: 0.1747\n",
      "Epoch 340/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2609 - accuracy: 0.1474\n",
      "Epoch 341/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0285 - accuracy: 0.1515\n",
      "Epoch 342/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1335 - accuracy: 0.1513\n",
      "Epoch 343/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1527 - accuracy: 0.1458\n",
      "Epoch 344/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0168 - accuracy: 0.1390\n",
      "Epoch 345/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4542 - accuracy: 0.1357\n",
      "Epoch 346/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2939 - accuracy: 0.1375\n",
      "Epoch 347/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1298 - accuracy: 0.1402\n",
      "Epoch 348/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1964 - accuracy: 0.1454\n",
      "Epoch 349/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1389 - accuracy: 0.1472\n",
      "Epoch 350/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1869 - accuracy: 0.1536\n",
      "Epoch 351/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5457 - accuracy: 0.1481\n",
      "Epoch 352/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7884 - accuracy: 0.1337\n",
      "Epoch 353/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3776 - accuracy: 0.1591\n",
      "Epoch 354/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.9289 - accuracy: 0.1414\n",
      "Epoch 355/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.7164 - accuracy: 0.1542\n",
      "Epoch 356/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4229 - accuracy: 0.1225\n",
      "Epoch 357/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5702 - accuracy: 0.1236\n",
      "Epoch 358/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4566 - accuracy: 0.1598\n",
      "Epoch 359/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4269 - accuracy: 0.1457\n",
      "Epoch 360/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4100 - accuracy: 0.1350\n",
      "Epoch 361/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5992 - accuracy: 0.1350\n",
      "Epoch 362/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4735 - accuracy: 0.1300\n",
      "Epoch 363/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4792 - accuracy: 0.1337\n",
      "Epoch 364/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6786 - accuracy: 0.1269\n",
      "Epoch 365/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3092 - accuracy: 0.1527\n",
      "Epoch 366/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4252 - accuracy: 0.1467\n",
      "Epoch 367/500\n",
      "53/53 [==============================] - ETA: 0s - loss: 6.5695 - accuracy: 0.13 - 0s 4ms/step - loss: 6.5526 - accuracy: 0.1416\n",
      "Epoch 368/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5436 - accuracy: 0.1431\n",
      "Epoch 369/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3970 - accuracy: 0.1517\n",
      "Epoch 370/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.5657 - accuracy: 0.1379\n",
      "Epoch 371/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.6241 - accuracy: 0.1250\n",
      "Epoch 372/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.4345 - accuracy: 0.1476\n",
      "Epoch 373/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.3441 - accuracy: 0.1485\n",
      "Epoch 374/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5816 - accuracy: 0.1531\n",
      "Epoch 375/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.2477 - accuracy: 0.1584\n",
      "Epoch 376/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.5967 - accuracy: 0.1474\n",
      "Epoch 377/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 6.2540 - accuracy: 0.1542\n",
      "Epoch 378/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2547 - accuracy: 0.1482\n",
      "Epoch 379/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2786 - accuracy: 0.1335\n",
      "Epoch 380/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1632 - accuracy: 0.1466\n",
      "Epoch 381/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.6024 - accuracy: 0.1687\n",
      "Epoch 382/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7034 - accuracy: 0.1590\n",
      "Epoch 383/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8030 - accuracy: 0.1530\n",
      "Epoch 384/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5859 - accuracy: 0.1606\n",
      "Epoch 385/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5810 - accuracy: 0.1714\n",
      "Epoch 386/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4350 - accuracy: 0.1575\n",
      "Epoch 387/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3409 - accuracy: 0.1635\n",
      "Epoch 388/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3243 - accuracy: 0.1596\n",
      "Epoch 389/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5999 - accuracy: 0.1534\n",
      "Epoch 390/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4535 - accuracy: 0.1534\n",
      "Epoch 391/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3439 - accuracy: 0.1568\n",
      "Epoch 392/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3683 - accuracy: 0.1633\n",
      "Epoch 393/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3048 - accuracy: 0.1564\n",
      "Epoch 394/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0532 - accuracy: 0.1602\n",
      "Epoch 395/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2048 - accuracy: 0.1528\n",
      "Epoch 396/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3032 - accuracy: 0.1419\n",
      "Epoch 397/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0133 - accuracy: 0.1549\n",
      "Epoch 398/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1166 - accuracy: 0.1548\n",
      "Epoch 399/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1332 - accuracy: 0.1576\n",
      "Epoch 400/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4829 - accuracy: 0.1379\n",
      "Epoch 401/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8133 - accuracy: 0.1420\n",
      "Epoch 402/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3266 - accuracy: 0.1507\n",
      "Epoch 403/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1474 - accuracy: 0.1407\n",
      "Epoch 404/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3981 - accuracy: 0.1453\n",
      "Epoch 405/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9757 - accuracy: 0.1654\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4481 - accuracy: 0.1298\n",
      "Epoch 407/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0856 - accuracy: 0.1449\n",
      "Epoch 408/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1589 - accuracy: 0.1370\n",
      "Epoch 409/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1779 - accuracy: 0.1385\n",
      "Epoch 410/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0114 - accuracy: 0.1501\n",
      "Epoch 411/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2214 - accuracy: 0.1441\n",
      "Epoch 412/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2597 - accuracy: 0.1408\n",
      "Epoch 413/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.8957 - accuracy: 0.1358\n",
      "Epoch 414/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3081 - accuracy: 0.1425\n",
      "Epoch 415/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0353 - accuracy: 0.1461\n",
      "Epoch 416/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2112 - accuracy: 0.1367\n",
      "Epoch 417/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9574 - accuracy: 0.1547\n",
      "Epoch 418/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2332 - accuracy: 0.1514\n",
      "Epoch 419/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2739 - accuracy: 0.1405\n",
      "Epoch 420/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.9758 - accuracy: 0.1466\n",
      "Epoch 421/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2936 - accuracy: 0.1426\n",
      "Epoch 422/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0778 - accuracy: 0.1451\n",
      "Epoch 423/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1161 - accuracy: 0.1560\n",
      "Epoch 424/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0763 - accuracy: 0.1427\n",
      "Epoch 425/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2400 - accuracy: 0.1488\n",
      "Epoch 426/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0326 - accuracy: 0.1456\n",
      "Epoch 427/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2277 - accuracy: 0.1418\n",
      "Epoch 428/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1312 - accuracy: 0.1434\n",
      "Epoch 429/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2442 - accuracy: 0.1349\n",
      "Epoch 430/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3395 - accuracy: 0.1392\n",
      "Epoch 431/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.0683 - accuracy: 0.1340\n",
      "Epoch 432/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2417 - accuracy: 0.1469\n",
      "Epoch 433/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0308 - accuracy: 0.1555\n",
      "Epoch 434/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0403 - accuracy: 0.1521\n",
      "Epoch 435/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1982 - accuracy: 0.1579\n",
      "Epoch 436/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3437 - accuracy: 0.1362\n",
      "Epoch 437/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1734 - accuracy: 0.1610\n",
      "Epoch 438/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.4009 - accuracy: 0.1345\n",
      "Epoch 439/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.2337 - accuracy: 0.1391\n",
      "Epoch 440/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1758 - accuracy: 0.1339\n",
      "Epoch 441/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1251 - accuracy: 0.1426\n",
      "Epoch 442/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0152 - accuracy: 0.1524\n",
      "Epoch 443/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2790 - accuracy: 0.1387\n",
      "Epoch 444/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0420 - accuracy: 0.1249\n",
      "Epoch 445/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9439 - accuracy: 0.1568\n",
      "Epoch 446/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.3140 - accuracy: 0.1458\n",
      "Epoch 447/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 5.9128 - accuracy: 0.1469\n",
      "Epoch 448/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 6.1971 - accuracy: 0.1615\n",
      "Epoch 449/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0861 - accuracy: 0.1453\n",
      "Epoch 450/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9721 - accuracy: 0.1439\n",
      "Epoch 451/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1920 - accuracy: 0.1413\n",
      "Epoch 452/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0723 - accuracy: 0.1555\n",
      "Epoch 453/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3238 - accuracy: 0.1500\n",
      "Epoch 454/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0760 - accuracy: 0.1502\n",
      "Epoch 455/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1808 - accuracy: 0.1561\n",
      "Epoch 456/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2303 - accuracy: 0.1504\n",
      "Epoch 457/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1947 - accuracy: 0.1420\n",
      "Epoch 458/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.2035 - accuracy: 0.1498\n",
      "Epoch 459/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8633 - accuracy: 0.1466\n",
      "Epoch 460/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0323 - accuracy: 0.1586\n",
      "Epoch 461/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0650 - accuracy: 0.1346\n",
      "Epoch 462/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2048 - accuracy: 0.1371\n",
      "Epoch 463/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7299 - accuracy: 0.1543\n",
      "Epoch 464/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0761 - accuracy: 0.1483\n",
      "Epoch 465/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1855 - accuracy: 0.1348\n",
      "Epoch 466/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7891 - accuracy: 0.1622\n",
      "Epoch 467/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1963 - accuracy: 0.1429\n",
      "Epoch 468/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0247 - accuracy: 0.1559\n",
      "Epoch 469/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1962 - accuracy: 0.1438\n",
      "Epoch 470/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9944 - accuracy: 0.1510\n",
      "Epoch 471/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.9407 - accuracy: 0.1487\n",
      "Epoch 472/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8660 - accuracy: 0.1658\n",
      "Epoch 473/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0814 - accuracy: 0.1587\n",
      "Epoch 474/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1580 - accuracy: 0.1440\n",
      "Epoch 475/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1425 - accuracy: 0.1560\n",
      "Epoch 476/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0290 - accuracy: 0.1634\n",
      "Epoch 477/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2621 - accuracy: 0.1305\n",
      "Epoch 478/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0781 - accuracy: 0.1546\n",
      "Epoch 479/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8480 - accuracy: 0.1445\n",
      "Epoch 480/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0753 - accuracy: 0.1450\n",
      "Epoch 481/500\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.0906 - accuracy: 0.1360\n",
      "Epoch 482/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1934 - accuracy: 0.1547\n",
      "Epoch 483/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0389 - accuracy: 0.1439\n",
      "Epoch 484/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1120 - accuracy: 0.1528\n",
      "Epoch 485/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0148 - accuracy: 0.1475\n",
      "Epoch 486/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.7724 - accuracy: 0.1561\n",
      "Epoch 487/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1364 - accuracy: 0.1398\n",
      "Epoch 488/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1528 - accuracy: 0.1521\n",
      "Epoch 489/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9139 - accuracy: 0.1575\n",
      "Epoch 490/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8297 - accuracy: 0.1656\n",
      "Epoch 491/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3171 - accuracy: 0.1430\n",
      "Epoch 492/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4441 - accuracy: 0.1472\n",
      "Epoch 493/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1499 - accuracy: 0.1470\n",
      "Epoch 494/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3346 - accuracy: 0.1548\n",
      "Epoch 495/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4068 - accuracy: 0.1522\n",
      "Epoch 496/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3453 - accuracy: 0.1333\n",
      "Epoch 497/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3205 - accuracy: 0.1494\n",
      "Epoch 498/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5877 - accuracy: 0.1549\n",
      "Epoch 499/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4443 - accuracy: 0.1458\n",
      "Epoch 500/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1210 - accuracy: 0.1715\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_x_gaf, training_t, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd5c2d83ed0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAy9ElEQVR4nO3deXiU5dX48e+Zmewr2dgCJOz7GtkERMWN+qpUrMurotX62lqr1tbXan92s7W2ttalleJWfbW2daFaFRVRVEB2QXYIa1iTECAbWWbm/v0xS2aSQBaSmTyT87muXGaeeZK5n0hOzpzn3PctxhiUUkpZny3cA1BKKdU2NKArpVSE0ICulFIRQgO6UkpFCA3oSikVIRzheuGMjAyTk5MTrpdXSilLWrNmTbExJrOx58IW0HNycli9enW4Xl4ppSxJRPae6jktuSilVITQgK6UUhFCA7pSSkUIDehKKRUhNKArpVSE0ICulFIRQgO6UkpFCMsF9G2Hy/jDR9s4Wl4d7qEopVSHYrmAvquonKc+yadIA7pSSgWxXECPifIMubrWHeaRKKVUx2K5gB7rsANQVesK80iUUqpjsVxA92XoVU7N0JVSKpD1Aro3Q6/WDF0ppYJYLqDHaoaulFKNslxAj9EaulJKNcpyAT02ylty0QxdKaWCWC6g17UtaoaulFKBLBfQfW2LmqErpVQwywX0KLsgojV0pZSqz3IBXUSIddg1oCulVD2WC+jgqaNryUUppYJZMqBrhq6UUg1ZM6BH2ajSxbmUUiqIJQN6jMNOtVMzdKWUCmTJgK4ZulJKNWTJgB6jNXSllGqgWQFdRO4RkU0islFEXhOR2HrPi4g8KSL5IvK1iIxtn+F6xEXbqazRgK6UUoGaDOgi0hP4AZBnjBkO2IFr6p12CTDA+3Eb8EwbjzNIemK07imqlFL1NLfk4gDiRMQBxAMH6z1/OfCy8VgOpIpI9zYcZ5DMxBiKy2swxrTXSyillOU0GdCNMQeAx4B9wCHghDHmo3qn9QQKAh7v9x5rFxmJMdS43JRWOdvrJZRSynKaU3LpgicDzwV6AAkicn390xr50gbps4jcJiKrRWR1UVFRa8YLQEZSNADFWnZRSim/5pRcZgC7jTFFxpha4C1gcr1z9gO9Ah5n07AsgzFmnjEmzxiTl5mZ2doxk5EYA0BxmQZ0pZTyaU5A3wdMFJF4ERHgfGBLvXPeAW70drtMxFOWOdTGY/XzBfSjFTXt9RJKKWU5jqZOMMasEJE3gLWAE/gKmCcit3ufnwu8D8wE8oFK4OZ2GzGQnuApuWhAV0qpOk0GdABjzM+An9U7PDfgeQPc0YbjOq2k2CgAyqpqQ/WSSinV4VlypmhslA2HTSjTLhellPKzZEAXEZJiHZqhK6VUAEsGdPCUXTRDV0qpOhYO6A4N6EopFcCyAT05NkpLLkopFcCyAV0zdKWUCmbhgK41dKWUCmThgO6gVEsuSinlZ9mAnhzroLzaidutS+gq1VZO1rj0d8rCLBvQU+KjMQbN0pVqI06XmyEPfcAv/rMp3ENRrWTZgN4l3jP9/1ilBnSl2oLTm5m/smJfmEeiWsvCAd2zQNfxSl2gS6m25NKSi2VZNqCnejP045qhK9UmdEdH67NwQPdk6Mc0Q1eqTZiGm4wpi7FsQO+iGbpSbUorLdZn2YCeHBuFiNbQlWorRmsulmfZgG6zCSlxUdrlolQb0Qzd+iwb0AG6Jcdy6MTJcA9DqcigAd3yLB3Qe6XFs6+kMtzDUCoiuLXkYnmWDui9vQFda39KnTn9LbI+ywf0qlo3ReXV4R6KUpanGbr1WTqg52QkALD9cHmYR6KU9Wk8tz5LB/RxfboQZRc+31EU7qEoZXlaurQ+Swf0xBgH43PTWLDxEE6XO9zDUcrSNJxbn6UDOsCcSTkUlJzkzbX7wz0UpSwtsIauC3RZk+UD+gVDuzIqO4UnF+Vrlq7UGQisuFQ7XeEbiGo1ywd0EWHO5BwOHD/J9iN6c1Sp1grMyatqNTmyIssHdICxvbsAsK7geHgHopSFBW49V6vvdi0pIgJ6n/R4usRHsWbvsXAPRamIUOPUgG5FERHQRYRJ/dJZml+srVdKtVLgTVGn3hS1pIgI6ADTB2ZxuLSKTQdLwz0UpSwpMBfSBgNripiAfsHQrsRF2Xlx6Z5wD0UpSwrM0GtdmqFbUcQE9C4J0VwxpgcfbDykPbRKtULgb43TrRm6FUVMQAeYkJtORY2LHYVl4R6KUpZjNEO3vIgK6GN6pwKwdu/xsI5DKSsKrKFr26I1RVRA750WT0K0XTN0pVrBHXRTVDN0K2oyoIvIIBFZF/BRKiJ31ztnuoicCDjnoXYb8enH6tnF6KjuYqRUS5mAKnqt1tAtydHUCcaYbcBoABGxAweA+Y2c+oUx5tI2HV0r9EmPZ1dRRbiHoZTlBMZwzdCtqaUll/OBncaYve0xmLbg25bOrZ0uSrVIYIaufejW1NKAfg3w2imemyQi60VkgYgMa+wEEblNRFaLyOqiovbZlKJvZiLVTjc7i3ShLqVaIuimqCZEltTsgC4i0cBlwOuNPL0W6GOMGQU8Bfy7se9hjJlnjMkzxuRlZma2YrhNmzGkKw6b8M9VBe3y/ZWKVDpT1PpakqFfAqw1xhyp/4QxptQYU+79/H0gSkQy2miMLZKZFMOlI7vz8pd7ydduF6WaLeimqAZ0S2pJQL+WU5RbRKSbiIj38/He73v0zIfXOg9+YyjxMXbue+NrnTWqVDO5g/rQ9ffGipoV0EUkHrgAeCvg2O0icrv34Wxgo4isB54ErjFhXPYwMymGhy4dytp9x3lp2Z5wDUMpSwn8ldWSizU12bYIYIypBNLrHZsb8PnTwNNtO7QzM2tMT95Zf5Dff7iNC4Z2pVdafLiHpFSHFjSxSN/ZWlJEzRQNJCL8ZtYI7DbhJ29t0HXSlWqSruVidREb0AF6pMZx38WDWJJfzDvrD4Z7OEp1aG7tcrG8iA7oAP89oQ+jeqXyy/9spri8OtzDUarD0j5064v4gG63Cb+7ciRlVU7uf1NLL0qdSvAGF5qhW1HEB3SAQd2SuO/iQXy85QiXPrWEqb/7hJKKmqBzKqqdvLlmv26OqzotnVhkfZ0ioAN8++xcpg3M5PCJKg4dr+LRBVuDnn/ui93c+/p6vv23VVRUO8M0SqXCx+hNUcvrNAHdZhNevOksVj44g1um5PLP1QV8ubNu7tOHmw7TNTmGZTuLeWTBljCOVKnwCMrQdflcS+o0AR089XS7TbhrxgByMxL44b/WcbyyhuLyajYfKuWmybnMmZzDK8v38eD8DVQ7XeEeslIhY3SDC8tr1sSiSBMf7eCJa0bzzb8sY/QvF/qPj8/twuheXYhx2Jn72U7W7D3GCzedRY/UuDCOVqnQcOueopbXqTL0QCOzU/nbzeO5bFQP/7HhPVOw24T7LxnMCzflUVBSyYPztTNGdQ6B/8q1y8WaOmWG7jNlQAZTBmRw69Rc9hytJMZh9z933uCu3HPBQB5+bwsfbynkgqFdwzhSpdpfYIauNXRr6rQZeqCR2alBmbrPnMk55GYkMPeznWEYlVIhpqstWp4G9NOIstu4+qxerNl7jM+3t88OS0p1FIEZui47bU0a0Jtw7Vm9Gdg1kTkvruTX722mqlY7X1Rk8sVzmwQHd2UdGtCbkBIfxVvfO5vrxvfm2S92c8kTX7BqT0m4h6VUm/MFcbtNNEO3KA3ozZAY4+DXs0bw6q0TqHW5+dZfv+SR97dotq4iii+E222CJujWpAG9Bc7un8GHd0/j2vG9+evnu7j86aUs2HCIyhpdKkBZn68912GzacnFojSgt1BCjIPfzBrBizefxbHKGr776lq++ZdlHNWleZXF+WK4llysSwN6K507KIuP7z2HX10xnD1HK5j1l2X8a3WBTkJSluX7l+vQkotlaUA/A8mxUdwwsQ9/u3k8JRU13PfG1/z6vS0a1JUlBd0U1X/DlqQBvQ1M7JvOhp9fyJxJfXhuyW5ueWl1g/XWlerofDHcYROtoVuUBvQ2IiL8/LJh/Py/hrIkv5jZzyxjy6HScA9LqWbzBXGbTdASujVpQG9DIsJNZ+fyyi0TKKt2cvnTS5n72U4KS6vCPTSlms1hE9wa0S1JA3o7GJ+bxgd3TWXawEx+u2ArEx5ZxG8XbNX11VWHFlhD15KLNWlAbyfpiTE8e+M4XrzpLK4Y3ZO5n+1k0E8/4M+f5od7aEo1qq6GbtO2RYvq1MvntjcR4dzBWZw7OIvLR/fgwfkbeXzhdmIcNm4+Oxe7TcI9RKX83NqHbnmaoYfI9EFZvP+DqUwflMXD722h3wPvc8PzK8gvLA/30JQCAmaK2rVt0ao0oIdQSnwUz944jsevHsXMEd1YV3CcS574nEc/2KrLB6iwC5wpqjV0a9KSS4iJCLPGZDNrTDbF5dX8dsFWnlm8kzfX7Ofa8b25e8YARLQUo0LP4FvLRWeKWpVm6GGUkRjDY1eN4o3bJ9E3M4EnFu3gxhdWsru4ItxDU52Q1tCtTwN6B5CXk8Zr35nILy4bxrp9x7nw8c94YP4G7QVWIaUlF+vTkksHISLMmZzDJSO68eiCbfx9xT6qal08MHMIGYkx4R6e6gR8JRe7zabJhEVpQO9gspJieeyqkXRNjmHe57tYsOEw103ozf9M60tWcmy4h6cimDtoLZfwjkW1jgb0DkhEuO/iwcwel83Tn+bzt2V7eHXFXuZMzuHcQVkM6ZZMSnxUuIepIo2utmh5WkPvwPpmJvLHb41m0Q/P4eJh3Zj3+S6umbecW19eRY3THe7hqQgTmKHrEtDWpAHdAnIyEvjTNWNYcNdUzhucxao9x5j++08577HF/PGjbeEenooQJmgtlzAPRrVKkwFdRAaJyLqAj1IRubveOSIiT4pIvoh8LSJj223Endjgbsm8cNNZvPTt8fRKi2dXcQVPfpKvm1WrNhGYoWvbojU1WUM3xmwDRgOIiB04AMyvd9olwADvxwTgGe9/VTs4Z2Am5wzMZMmOYq5/fgXnPbaYkdmp3Do1l7yctHAPT1mUL4TbdZNoy2ppyeV8YKcxZm+945cDLxuP5UCqiHRvkxGqU5oyIIPHrx7F8J4prN57jKv++iX//upAuIelLMq/louuh25ZLe1yuQZ4rZHjPYGCgMf7vccOBZ4kIrcBtwH07t27hS+tGuNbRqCyxslNL67ix2+s50hpFbdO7aurOaoW8U8ssmsN3aqanaGLSDRwGfB6Y083cqzBPwljzDxjTJ4xJi8zM7P5o1RNio928OyNeZwzMJNHFmzl7n+us2yWVVhWxdp9x8I9jE7Hv8GFaNuiVbWk5HIJsNYYc6SR5/YDvQIeZwMHz2RgquVS4qJ4bs5Z/PiiQfxn/UFufXm1JW+Y/tdTS/jmX5aFexidTl0NXdsWraolAf1aGi+3ALwD3OjtdpkInDDGHDrFuaqdfW96P376jSF8srWQa59dzpq9JeEeUoscKa0GwOnSXvtQcgfW0DWeW1KzArqIxAMXAG8FHLtdRG73Pnwf2AXkA88C32vjcaoWEBFundqXJ64ZTUFJJVc+8yV3/H0t+49VhntoLVJerWvEh1JgDV3bFq2pWTdFjTGVQHq9Y3MDPjfAHW07NHWmLh/dk/OHdOWFJbt5+tN8Fm46wg8vHMh3LHLDtKzKSWp8dLiH0ek4vP82jDG6Nr/F6EzRCJcY4+AH5w9g8Y+mc97gLH67YCtXzV3Gc1/s4khpVYcua5RW1YZ7CJ2K7ya63eYJC5qlW48G9E6iR2ocz1w/lseuGsWWQ2U8/N4WJvxmEY9/vD3cQzulsiotuYSSL3z7MnSN59ajAb0TERFmj8tm5YPnk5uRAMCfP93Z4dobfeUgDeih5Q5YyyXwsbIODeidUFJsFO/9YAoPzhwCwB8Xbu9QbWoOf0DXkksoBe5YBBrQrUgDeicVH+3g1qm5fHNsT57+NJ9r5gW3N4Zzed5ou+efpWbooWUCJhaBllysSDe46MREhD9cNYoxvVJ58pN8rnzmS3qkxHLx8O68sHQ37945heE9U0I+riiHDao1Qw81A9gEfI0telPUejRD7+REhBsm5bDo3nOYPS6bgyeqeGHpboCwLfTlCyQnTmpADyW3t03RHtC2qKxFA7oCIDk2iseuGsWqB2cwICsRgPlfHWBPcUXIx+JbrqC4vCbkr92ZGePJ0G3eFF0zdOvRgK6CZCbF8NE90/j4h9NwG8N1zy5nxa6jIXt9YwzV3vp9YVlVyF5XeWrmguCbc6bx3Ho0oKsGRIT+WUn83y0TcNhtXD1vORc9/jkfbTrc7q9dHXAzttC7posKDYMBAZuWXCxLA7o6peE9U/jg7qn8z7S+bDtSxr2vr+cfK/exvuB4u71m4OqQR0o1Qw+p+iUXDeiWowFdnVZ8tIOfzBzCF/edS7fkWO5/awNXPrOMJTuK2+X1qmo9GXrP1DhKq5yWXP7XqtzGIIi2LVqYBnTVLL3S4llw11ReuWUC3VNjmfPiSv5vef2dCFvntwu28vcV+4C6DL1PejygZZdQ8t0U9bUtdrQZxKppGtBVsznsNqYMyOD9H0xl2oAMHnp7I3/8aNsZ/+LP/WwnD8zfAECV0xPQ+2V6Om2stuSvlbkNQW2LOlPUejSgqxZLio3iqevGct6gLJ78JP+MFviqf+OtssYT0Id0TwZgz1EN6KFiMIi2LVqaBnTVKokxDp6bk8fVeb146pN8/rW6oOkvakTpyeDp/Se9AT03I4Foh429R0PfB38qVbUuvvPyanYWlYd7KO3CeJpc6kouGs8tRwO6ajUR4eFZw5nSP4P/ffNr3lizv8Xfo6g8uEbuy9ATYxz0SYtnTwcK6Kv2lLBw8xEeentjuIfSLowx2Gw6U7QtfbXvGDn3v8eWQ6UheT0N6OqMRNltPDcnj8n90nngrQ3kF5a16OuPBgR0YwyVNZ6MPS7aRnaXOPYfO9mm4z0TvkDndEVmoHN7M3RtW2w7Ly7dA8DX+4+H5PU0oKszFhtl54lrxhAbZWP23C95+N3Nze4hD5zeX1Xr9pdc4qIdZCXFUlTWcbpcHN6dfCL1ZqHBYBPxB3R3x93MyjI2HTwBeGZgh4IGdNUmMhJjeO22iZRXOXluyW5++e7mZn1dcUCGfuJkrb/kEh9lJys5huLy6g5zc867qi/ODjKetubpciFg6n9kXmco7SzylAxDtdOjBnTVZob1SOHfd5xNRmIM7284xJ2vfcWhE6cumew/VsmS/LoJSidO1nKy1peh28lKisFt4GhFx8jSfb+UHeUPTFsz2rbYblwherujAV21qeE9U3jn+2czMCuJ/6w/yPf//pW/Ll7flEc/ZeHmI/7HngzdiU0gxmHzv03tKGWXWm9Ej9QaujEmqIYeoX+3wkIzdGVZPVLj+PCeaTx93Ri+2neMG55fSWFZVVDXRGMThgrLqjhZ4yY+2oGIkJkU6z3esQJ6JGboVbUu/rGqgJO1rjPa4OI3728h5/732nh01ufUDF1Z3aUje/D0dWNZs/cY43+9iO+8vMa/td26gAW+srvEAVBQcpKTtU7iou0A9OoShwi88uVeqp3hX9Ol1puZh+qXM5Te/foQ4Nn270zaFud9vguAE5W6OUmgUCUBGtBVu5o5oju/nz2SGUO68vGWI5z3h8X8/sOt7Cupy9Cj7Ta6xEdRcKySyhoX8d6AnpUcyy8uG8airYX86eMd4boEP2cEZ+hJsXW7UZ7JTNGMRE+ZrECXbAgSqhvpGtBVu7sqrxfPzcnj8atHcaKylj9/upPffbDN/3yNy02vtHgKSjwBPS7K7n/uxkk5TOmfwadbCxt8X2MMH2067A+07a3GV0OPwIAeuB7PmdTQe6Z6ymSBf7CVZugqAs0ak83iH09vcLx/ViK9unhmhZ4MyNB9JuSmsfVwGccqgrek+2jzEW77vzU8+8Xu9hy2n+9maCSuQlgVUNI6k7bF7ime8pkG9GCaoauIlJ4Yw9ZfXQxAt+RYXrzpLJ64egwT+qZRUHKS1XtLiI92BH3N1IGZAHy0OXjHpH3ehbtC9fa+NoIz9GrvOvQf/3Caf8ei1gT02ChPSNmri6oFcYXoXaQGdBVysVF23vzuZF6/fRLnDs4iJT6Kb4zoDnhmiw7omhh0/qjsFPplJvDyl3uDsuMDxz097rXO0Pyy1HpfOxJr6L516NMTYs6o5OL7GRVohh5k6c6jXPj4Z+2+YYsGdBUW4/p0oVdavP9xemKM/8bchNz0oHNFhO9N78+mg6Xc+vJq8gs9qx1uP+JZNyZUb+99fzgiMUOv8l5bTJStruTSiut0ectSzf1/UlpV63/nE4l8LaCbD5ay/Uh5u2/YogFddRhPXzeWfpkJTO6f3uC5WWN6cs+MgazaU8KPXl8PwPYjnsC+s6ii0eDzk7e+5qVle9psfL52xUjM0H0ll1iH/Yxmivp+RgeOn2zWzeqRP/+I7/99bYtfxyp873Z8m5+XVbdvO6cGdNVhnDMwk0X3Tic5NqrBczabcNeMAdw9YyDrCo6zcPMRisurGd4zmeLyar7cdTTofKfLzWsrC/jZO5vaLAOM5D70KqeLaLstaPnc1vzcfD8jl9v4S2JN+XDTkaZPsihvgu6fR1Fe1fis6baiAV1ZylV52WR3ieMOb1b3/XMHkJEYzQPzN1BYVrfCY+Bb/tV7jjXre7vdhl+9u5kdRxpfAtg3KarG6Y64MkFVrYsYhycc+HrJi8prTvcljXK5DdHe7/P1/hOnPbczrbfu+7dTXq0BXSm/5NgoXvr2eLK7xGETGN0rlXk35lFYWs2cF1Zx4qTnLa2vzg6Q38wdhvaWVPL8kt28corNr32ZudsQsg0LQqWq1k2Mt/8/PSEam0BRM5dADlTrcjOiZwpxUXbW7D39H9JILF3V5ytbVWtAV6px/TITeef7U3j7jil0S4llbO8uzL1hHPmFZcx5YSW7isrZcqguy97VzIC+u9hzXv3yjU9twKJczc36raLa6fK3HDrsNjISYzjSiht4TrchNsrG6F6pLD/FzzHw3EhmjGnQKVTaEUouIpIqIm+IyFYR2SIik+o9P11ETojIOu/HQ+0zXKU8EmMcjMhO8T8+Z2AmT107hp2F5Vz0p895Yelu8vp0YUTPFP+a1E3Z5T1v+5HyoHXafWpdbpJiHPROi+eLHUVtcyFtaMWuo61ui6uudftLLgBdk2M5UtbyDN3pNthtNqYPymTr4bLT1tEjP6A3PNZRauhPAB8YYwYDo4AtjZzzhTFmtPfjl202QqWa6eLh3fnkR9OZPa4X5dVOrp/Yh2E9klm9p6RZOygF7l/aWHZZ63IT5bBxwdCuLM0/SllVx1mAau/RCq6et5wH57duv9OqWhexAUsudE1uZYbuchNlE84fkgXAF9tP/YcvVEs2hEtjW/iVh7vLRUSSgWnA8wDGmBpjzPF2HZVSrZSZFMMj3xzBpl9cxBVjenL7Of1wugyPfrC1ya/deKCUsb1TSYxx8IePtjfY9NrpMjhswkXDulHjcrN4W8fJ0su8md/mVtb2q5z1A3osB45VtvjGpcttsNuEvhmJJMY42HTw1OMJzNDbe8JNODTW9tkRMvS+QBHwooh8JSLPiUhCI+dNEpH1IrJARIY19o1E5DYRWS0iq4uKOs4vg4o8vuCUk5HALVNzeWvtAX717mb+sjifPcXBJZh1Bcf59Xub2XjgBJP6pXPhsK7sLq7gR6+vD8oia1xuouw2xvXpQnpCNB9t7jjtdv7e8VaWMeqXXIZ0T6a0ytniTbprvT8jm00Y0j3ptDePAzcKKT3Zcd7ttJXGulvLOsBNUQcwFnjGGDMGqADur3fOWqCPMWYU8BTw78a+kTFmnjEmzxiTl5mZ2fpRK9UC98wYyOxx2Ty/ZDe/+2Ab1z+/wl8ucbsNV/x5Kc9+sRun23BWThp3nz/Q/7XbAloYnS5DlN3Tpz1jSFc+3VrYIdZph7pssLXbxtXP0EdlpwKwvoW71TvdBofd88dlSPdkthwqPWU3S2DrZ3ErWiQ7usb+X5R1gAx9P7DfGLPC+/gNPAHezxhTaowp937+PhAlIhltOlKlWinaYeOxq0bx0T3TeHDmEA6dqOKWl1azNL+YrYeDe85HZqfSOz2eL+47F4AVu0r8z/myT4CLhnelvNrJsvyjHaKf2tfn3OqAXuv2d7kADOqWRFyUnfe8G180l9Nl/O8W8nLSqKhxBW1mEigw0DfnHofVNFpDD3dAN8YcBgpEZJD30PlA0JbuItJNxDPHVUTGe7/v6XuWlAqxgV2T+M60vjx65Ui+3n+c/35uBTOf/CLonLSEaMCzi9LoXqn8+dN8/7K9tS7jD+hn988gLSGam/+2inEPf8y2w41PRgqVuoDeuq8/WeMi1lGXoUc7bHx3ej8WbDzMil1HcbkNa/aWnOY7eDjdbqJsnp/RtAEZ2AQ+29ZwLXvfuT6HIzCgm0ZKLh2lD/1O4FUR+RoYDfxGRG4Xkdu9z88GNorIeuBJ4BrTEdIWpRoxe1w2a//fBVyd1+uU54gIj3xzBCdO1nLDCysoLKvyZuie7DPGYeeWKbkAlFTU8O7XB0My9lPxbb7R2gy9osZJQkzwssW3TetLVlIMT3+az+urC7jymS+bvE6nq67kkhofzdAeyaw+xQSjwJuih09EXkBvvMulfQO6o+lTwBizDsird3huwPNPA0+33bCUal/x0Q4enT2S3unxGOOZrj6ke3LQOUO6J/PolSO59/X1PPL+VqqdLn+GDvC96f24Ki+b776ylqc+yWd8bhpTB4Tn3tCZllwqq10NAnpslJ1v5fXiL4vzyUzyLAfw0rI9XDi0m396f31Ot6cTyGd0r1T+/dVB3G7jX2fdf64rwksujbxd6gg1dKUi1h3n9uf75w3gtmn9Gg3GV47L5ptjezL/qwMs31VC38y6Bi8RISsplge/MYTU+Ch+9vYm/9IDoeYP6K1o7a5xuqlxuUmMsTd47tJR3XEbeGvtAQBW7TnGP1ft876WabAZtNPlxhHwR290ry6UVzvZXtiwJBWUoUdgQG+sSNHecxc0oCvVhN/MGsHDVwxnxpCu3Hfx4AbPj+3dhcdmj2JvSSV5Dy/kpWV7Qn6j9ExKLhXeMkD9naIABndLZlJfz3LGs8b0pGdqnH9phHfWH2TybxcFBfX6GfqU/hmIwIcbG7Z4+lpCbQLHKiOvbbGxkku10+3/49seNKAr1YTYKDvXT+zDc3Py/CsR1jdjaFeevGYMtS7Dz97ZxLXPLucfK/eFrK2x+gxKLhU1noCeGNN4BfbhWcO587z+3HFuPybkprFydwnGGPYeraSixsXXB477zw1sWwTolhLL+Jw03t/QsFvGl6Gnxkf7/6hEklPdoG7Pa9WArlQb+cbI7qx84HwemDmYQyequP+tDdz28hr2h2DPU1/W15rZ9BXVnj868Y2UXMCzGNq9Fw6if1YSY/t0obi8hv3HTlLqLR/4lsk1xuByGxy24LBy3uAsth0pa1An99XQU+KiIjOgnyKit+eNUQ3oSrWhrORYbpvWj8U/ms6PLxrE5zuKuGrul6fsxW4rvoDemlKPL8DUvynamBE9PQuibTxwwj+7c+MBT0D3ZdyOejc/z+7vmZKybGdx0PFab8E/JS6qzfuzl+0spqQivJOVTvVuqT1vjGpAV6odiAh3nNufd++cgk2EK/68lG/N/ZKnP9nR4EZiW/DV0Bur2zalsomSS6BB3ZJw2IT1+080yNB9GXfgTVHwdAvFRtnYdCB4GQBXYIZe42yz+w5Ol5vrnl3Bfz+3oumT29GpZsi2541RDehKtaNhPVJ4/fZJjO6VyuHSKh77aDtX/GUpTy3awRc7iqiqdTW5brjPgeMneWrRjkYDX12XS/OC4htr9nPeY4sxxgTcFG285BIoNsrOxL7p/Gt1gX+dlwPHT1JSUePPuOtn6Hab0D8rMWgZBaibWJQaH4XbwMk2WqDLt+F1uDchqf+/wjeD9jsvr+btdQfa5TWb1YeulGq9Hqlx/PuOswFYll/MjS+s5A8Ltwed83+3jG+yh/3uf3zFqj3HuHh4NwZ0TQp6zhfQAzfhOB3fRtuVNS5/Db05GTrAXTMGcNXcLympqCEp1kFZlZMNB04w0luOCbwp6jOwaxJL84NLLv6bonGePWTLq52Ndtq0VHUHWbmxfsmle0qs996Dk31H2+e+imboSoXQ5P4ZLLr3HJ67MY9zBtYF8D99vKPJry096cmkjzZSG/aVXKqcrmaVLnwTg0oqavxdLs2poYNnspBv3ZcJuZ6Wxg37j9dl6PaGYWVo92SOlFZz6ETd6o3+m6LxnuUWfH9YzlRVO7YFtkRjAd2nT0ZjC9aeOQ3oSoVYn/QEZgztyvNz8vhWXjYXDu3Kmr3HuPnFlfxrdQF7j1Y0WjrxZb6NTZOvuyna9ObMALHegH6ssqbupmgzs+Mou42RPVMBz5o3fTMS2HDghL9mXL/kAjB9kGfDi4UBSw43yNDb6GZhR1lb3ffz8P04Art/+qTFt8trakBXKkwcdhu/mz2Kx68ezZVjs1mSX8x9b3zNOb9fzDeeWsJn9Xb78QXKgycarlFe7XQT7bDhsAkLNh5u8rXjvPXykooaKqtd2ISg1Rabcp53R6IDx08yIjuFNXuPUVnjChpnoP5ZifTPSuSDgLH5JhalBJRc2kJHCei+Wbu+d0OBpaicdM3QlYpICTEO/vCtUax4YAbzbhjH7ef0o/RkLbe+tIqr5i7jX6sKOFJa5Q94h44HZ+iFZVW8tnIfybEOxvbp0qA9sDG+tc99GXpCtAPvgqnN8i3vwmYzR3TjyrHZFJfX8M9VBUDjNXSAi4d1Y8XuEn87Yd3EIk9Ab6sFzqo7WMnFt/6PTYS8Pl0ASPFec1vTgK5UB5GWEM2Fw7px/yWD+c+dU7hxUg5HK2q4782vmfTIIv9m11sPB3dvPLUoH/BsEjExN42NB040me36lso9Wl5DRXXDlRabM9bdj8xk1phspg7IYFSvVOZ9vguAuKjGu2VmjuiOy214a61naz9fhp7qraG/umIfRxvZnLulOkqG7msh9f3xdNiEl28Zz/KfnN9ur6kBXakOKC0hmv936VA+vHsab353sn9yTnpCNKv2HOOPC7ez8cAJT8mkpi6ATe6fgdvAq8v3UniaBa98WfSxSs/XJ5xilujp+DJ6EeHOc/v7j/tulNY3tEcyZ+V04ZXlezHG+DP0/lmJXDaqBwBL8pt+d9GU6tqOkaH7bk4neMtbNpsQH+2gW8DN0bamAV2pDsy3h+lLN49nwV1T+c+dUxjSPZknF+3g0qeWMPOJL3jrq7rNrCfkpjG6VyqPLNjKlEc/PWUvtq/n+9BxTymnpRl6fecPyaJbcix5fbrQxbtJSGNmjclmz9FKdhSW+wN6tN3Gn64eTWp8VIPWxtboMBm69++KrxWzsXsLbU0DulIW4Nl0OZkeqXEsuGsq7/1gCpcM70ZZVS3GeGrZH//wHESE5+fk8b8XD6bW7eaP9frdfU56s/qlO4v9NfQzISJ8+qPpvHLrhNOed773Zur8rw74Sy52m2CzCaN7pbK+oOkOnaZUBSyI1tpNs9uCr4bu6++vvx58e9CJRUpZ0LAeKTxz/TjKq53sOFLGsB4p/m6K9MQYvju9HwePn+TNtfupdrqIcQSXVCprXMRH2zlSWs3R8hp/W+GZiGvGTNOuybFcNqoHLy7dzRWjewJ1meuo7FQ+376jVTX9QIEll5O1DTfuCBXfHxPfomfO1qyc1kKaoStlYYkxDsb07tLoDkLnDs6kssbF/LUNp5lX1jj965w73aZVNfTW+vFFg3Ab+MeqAmxSl7mO7p2K28DafY1vWddcgSWX9t4h6HR8bw58f1CaO4v3TGhAVypCTRuQyaS+6Tz0ziZeXLrbnyHWutzUugxDeyT7J72EMovtlRbPJcO7AcGTbSbkphHtsLF4W9GpvrRZAmeKHjjesGc/VFz1borWaoaulGoth93G09eNoW9GAr/4z2aumbecl5btYdthzyJZKXFR9PbOWExoRrmkLU3xdu3UBAS5+GgHE3LTWLyt8Iy+d2CGXlDS/mvRn4qvhu77YxmK/ngN6EpFsPTEGD64exp/uno0OwrL+dk7m7j0qSWAJ4D2y0wE6nqlQ+VUNfvpg7LYWVRxRoE4MHDuC2dAd/sydF/JRQO6UqoNXDGmJ+seuoCF90zzHxuf24XLx3huTJaGeHPrzKQY/vLfY7ltWt+g4+cO8ixY9s76hrNG3W7TrIXHqmpdJMU46JocE9aA7lvLpa6G3v4BXbtclOokRIQBXZP46w3jqHa66Z+VRN+MRI5X1nDRsG4hH8/MEd2ZOaJ70LG+mYmcNziLP3+aT7/MBC4a1g0Rwely0//BBdx5Xn/uvXDQab9vVa2bmCg7A7KSWO/dKaqwtIqs5Pab0NOYupuinnc/7bk5tI9m6Ep1MhcN6+afmWmzCTdOyqFriIPd6fxm1ggGZCVy+ytr+a+nl/DFjiL/5hhPfZLf5NefOFlDcpyDGUOy2FFYzuMLtzP+N4t4cenu9h56EH8NPVq7XJRSnVS3lFhev30yv7piOMcra7nh+ZXc9vIa//O+LfNO5eDxKnqmxjFzZHcSYxw8sciz1vzjC7e3ehbpTS+u5JnFO1v0NfVvimqGrpTqlKIdNm6Y2IdF957DT78xJCgQB66p3piDx0/SPSWWrKRYHrtqFADdkmMprXLyURNf2xi327B4WxGPfrC1RV9XV0MPXdui1tCVUh1WjMPOrVP7cv3EPlTXurn06S/43ze/5u11B5nUN52xfbowomfdLNkap5ui8mp6pMYBcPHwbrz07fH0z0rk6r9+yT9X7fOXm5rr8GkWOTsd3/3b+BB2uWhAV0p1eLFRdmKj7Dw/5yxeXb6Xz3cU88lWT796tMPG6OxUsrvEISIYgz+gA/6t/q4d35vff7iNF5bs5qbJOc1eW6W1nTK+DN23nLCtBevNt5YGdKWUZQzsmsQvLh8OeDb2WLPnGKv3ej6W7Tzqz6YH1dtEG+Dms3P41+oCfvnuZnYVlzN7XC9y0xNIiY/C5TYIjS+gFbih88kaV7PWrIG6GnpSrIO7zh/QoKOnPWhAV0pZUlZSLJeM6M4lAYGyrKqWaqebjMSYBufHRzv48O5pPPT2Rl5Zvo9Xlu8DoEdKLGVVTob2SOZvN49vELB3FVf4Pz9cWkVuMzd49gV0m02454KBLb6+1tCArpSKGEmxUTTMzevERtn53exRfP/cAWw9XMqeoxWs2FXCoq2FrNhdwrmPLeb8IVlMHZDJoG5JJETb2RywpvzzS3bx8BUjmjUWXx+6PQSlFh8N6EqpTqd3ejy90z3r2Nw2rR8AS/OLeXHpHuZ/dYBXV3iydxHPzc3Z47KJjbLxj5UF3Dgphx6pcf51zk/FV0MPwTLofhrQlVIKOLt/Bmf3z6Da6WLD/hPsOVrJv1YVsHJPCaOyU5jQN51Xlu/jwsc/Z0TPFN763mSqne4Ggf14ZQ2xUfagkkuoaEBXSqkAMQ47eTlp5OWkMWtMT9bsPcboXqlEO2w8fMVwfvrvjWw4cIIBDy4g2m7jnTvPZnC3ZMCzj+joXy5kQm6af4ngUHS3+GhAV0qpU7DbhPG5af7H10/sw/UT+zD/q/38dP5GKmpc3PrSam6dkkuf9AQKyzxdNit2lzDRu4GI1tCVUqoDmzUmm1ljslm2s5hHP9jGz/+zucE5vqUCbCGcj9+sgC4iqcBzwHDAAN82xnwZ8LwATwAzgUrgJmPM2jYfrVJKdSCT+2Xw9h0ZbD5YyrqC4xSXV1NSUUNpVS1vebf+64gllyeAD4wxs0UkGoiv9/wlwADvxwTgGe9/lVIq4g3tkczQHsn+x1W1LnqkxOE2hvgQ7gbVZEAXkWRgGnATgDGmBqipd9rlwMvGs/r8chFJFZHuxphDbTxepZTq8GKj7PzootOv294emlPd6QsUAS+KyFci8pyI1J8q1RMoCHi833ssiIjcJiKrRWR1UdGZbQSrlFIqWHMCugMYCzxjjBkDVAD31zunsSJRg9XcjTHzjDF5xpi8zMzMFg9WKaXUqTUnoO8H9htjVngfv4EnwNc/p1fA42yg4aaASiml2k2TAd0YcxgoEBFfQeh8oH6PzjvAjeIxETih9XOllAqt5na53Am86u1w2QXcLCK3Axhj5gLv42lZzMfTtnhzO4xVKaXUaTQroBtj1gF59Q7PDXjeAHe03bCUUkq1lO4pqpRSEUIDulJKRQgxpkF3YWheWKQI2NvKL88AittwOFag19w56DV3DmdyzX2MMY32fYctoJ8JEVltjKlf049oes2dg15z59Be16wlF6WUihAa0JVSKkJYNaDPC/cAwkCvuXPQa+4c2uWaLVlDV0op1ZBVM3SllFL1aEBXSqkIYbmALiIXi8g2EckXkfrL+FqWiLwgIoUisjHgWJqILBSRHd7/dgl47ifen8E2EbkoPKM+MyLSS0Q+FZEtIrJJRO7yHo/Y6xaRWBFZKSLrvdf8C+/xiL1mABGxe/dTeNf7OKKvF0BE9ojIBhFZJyKrvcfa97qNMZb5AOzATjybbkQD64Gh4R5XG13bNDzLEm8MOPY74H7v5/cDj3o/H+q99hgg1/szsYf7Glpxzd2Bsd7Pk4Dt3muL2OvGs3dAovfzKGAFMDGSr9l7HT8E/g68630c0dfrvZY9QEa9Y+163VbL0McD+caYXcazFd4/8Gx/Z3nGmM+BknqHLwde8n7+EnBFwPF/GGOqjTG78axyOT4U42xLxphDxruZuDGmDNiCZ6eriL1u41HufRjl/TBE8DWLSDbwDTwbzftE7PU2oV2v22oBvVlb3UWQrsa7rrz3v1ne4xH3cxCRHGAMnow1oq/bW35YBxQCC41n85hIvuY/AfcB7oBjkXy9Pgb4SETWiMht3mPtet3NXQ+9o2jWVnedQET9HEQkEXgTuNsYUyrS2OV5Tm3kmOWu2xjjAkaLSCowX0SGn+Z0S1+ziFwKFBpj1ojI9OZ8SSPHLHO99ZxtjDkoIlnAQhHZeppz2+S6rZahd7at7o6ISHcA738Lvccj5ucgIlF4gvmrxpi3vIcj/roBjDHHgcXAxUTuNZ8NXCYie/CUSM8TkVeI3Ov1M8Yc9P63EJiPp4TSrtdttYC+ChggIrne3ZOuwbP9XaR6B5jj/XwO8HbA8WtEJEZEcoEBwMowjO+MiCcVfx7YYoz5Y8BTEXvdIpLpzcwRkThgBrCVCL1mY8xPjDHZxpgcPL+vnxhjridCr9dHRBJEJMn3OXAhsJH2vu5w3wluxZ3jmXi6IXYCD4Z7PG14Xa8Bh4BaPH+tbwHSgUXADu9/0wLOf9D7M9gGXBLu8bfymqfgeVv5NbDO+zEzkq8bGAl85b3mjcBD3uMRe80B1zGdui6XiL5ePJ14670fm3yxqr2vW6f+K6VUhLBayUUppdQpaEBXSqkIoQFdKaUihAZ0pZSKEBrQlVIqQmhAV0qpCKEBXSmlIsT/B5+veIQ218g2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - loss: 6.3160 - accuracy: 0.1500\n",
      "Train accuracy: 0.15000000596046448\n",
      "\n",
      "14/14 - 0s - loss: 7.6954 - accuracy: 0.0929\n",
      "Test accuracy: 0.09285714477300644\n"
     ]
    }
   ],
   "source": [
    "eval_model(training_x_gaf,training_t,testing_x_gaf,testing_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on Audio Phonemes, Test on Thinking Phonemes / vice versa\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x: 4560 Train t: 4560\n",
      "Test x: 4560 Test t: 4560\n",
      "training_x: (4560, 13, 14)\n",
      "testing_x: (4560, 13, 14)\n",
      "training_t: (4560,)\n",
      "testing_t: (4560,)\n",
      "(14, 14, 13) \n",
      "\n",
      "(4560, 14, 14, 13)\n",
      "(4560, 13, 14)\n",
      "(4560, 14, 14, 13)\n",
      "(4560, 13, 14)\n"
     ]
    }
   ],
   "source": [
    "#Stack all samples into single matrix\n",
    "x_train = [] #listening\n",
    "t_train = [] #listening\n",
    "x_test = [] #think\n",
    "t_test = [] #think\n",
    "\n",
    "for phone in range(len(structured_dataset_listen)):\n",
    "    for sound_packet in range(len(structured_dataset_listen[phone])):\n",
    "        \n",
    "        x_train.append(structured_dataset_listen[phone][sound_packet])\n",
    "        t_train.append(phone)\n",
    "        \n",
    "        x_test.append(structured_dataset_think[phone][sound_packet])\n",
    "        t_test.append(phone)\n",
    "\n",
    "print(\"Train x:\",len(x_train),\"Train t:\",len(t_train))\n",
    "print(\"Test x:\",len(x_test),\"Test t:\",len(t_test))\n",
    "training_x,training_t,null3,null4 = split_data(x_train,t_train,training_size=1) #all listening training data\n",
    "null1,null2,testing_x,testing_t = split_data(x_test,t_test,training_size=0) #all think testing data\n",
    "\n",
    "print(\"training_x:\",training_x.shape)\n",
    "print(\"testing_x:\",testing_x.shape)\n",
    "print(\"training_t:\",training_t.shape)\n",
    "print(\"testing_t:\",testing_t.shape)\n",
    "\n",
    "training_x_gaf = to_gaf(training_x)\n",
    "testing_x_gaf = to_gaf(testing_x)\n",
    "\n",
    "input_size_gaf = training_x_gaf.shape[1:]\n",
    "print(input_size_gaf,'\\n')\n",
    "print(training_x_gaf.shape)\n",
    "print(training_x.shape)\n",
    "\n",
    "print(testing_x_gaf.shape)\n",
    "print(testing_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_16 (Flatten)         (None, 182)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1000)              183000    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 15)                15015     \n",
      "=================================================================\n",
      "Total params: 4,202,015\n",
      "Trainable params: 4,202,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(input_shape)),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(15, activation=tf.keras.activations.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tf.keras.backend.set_value(model.optimizer.learning_rate, 0.000025)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "143/143 [==============================] - 4s 18ms/step - loss: 2.6295 - accuracy: 0.1245\n",
      "Epoch 2/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 2.4371 - accuracy: 0.2450\n",
      "Epoch 3/50\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 2.2281 - accuracy: 0.3212\n",
      "Epoch 4/50\n",
      "143/143 [==============================] - 3s 19ms/step - loss: 2.0331 - accuracy: 0.3877\n",
      "Epoch 5/50\n",
      "143/143 [==============================] - 3s 20ms/step - loss: 1.8352 - accuracy: 0.4470\n",
      "Epoch 6/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 1.6527 - accuracy: 0.5161\n",
      "Epoch 7/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 1.4911 - accuracy: 0.5655\n",
      "Epoch 8/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 1.3404 - accuracy: 0.6210\n",
      "Epoch 9/50\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 1.1974 - accuracy: 0.6693\n",
      "Epoch 10/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 1.0554 - accuracy: 0.7096\n",
      "Epoch 11/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.9252 - accuracy: 0.7674\n",
      "Epoch 12/50\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.8297 - accuracy: 0.7942\n",
      "Epoch 13/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.7499 - accuracy: 0.8175\n",
      "Epoch 14/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.6687 - accuracy: 0.8428\n",
      "Epoch 15/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.5773 - accuracy: 0.8665\n",
      "Epoch 16/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.4946 - accuracy: 0.8994\n",
      "Epoch 17/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.4335 - accuracy: 0.9106\n",
      "Epoch 18/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.4052 - accuracy: 0.9198\n",
      "Epoch 19/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.3511 - accuracy: 0.9327\n",
      "Epoch 20/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.2962 - accuracy: 0.9526\n",
      "Epoch 21/50\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.2670 - accuracy: 0.9539\n",
      "Epoch 22/50\n",
      "143/143 [==============================] - 3s 19ms/step - loss: 0.2427 - accuracy: 0.9592\n",
      "Epoch 23/50\n",
      "143/143 [==============================] - 3s 19ms/step - loss: 0.2005 - accuracy: 0.9733\n",
      "Epoch 24/50\n",
      "143/143 [==============================] - 3s 19ms/step - loss: 0.1862 - accuracy: 0.9682\n",
      "Epoch 25/50\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.1549 - accuracy: 0.9797\n",
      "Epoch 26/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.1483 - accuracy: 0.9803\n",
      "Epoch 27/50\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.1210 - accuracy: 0.9884\n",
      "Epoch 28/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.1051 - accuracy: 0.9927\n",
      "Epoch 29/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.1044 - accuracy: 0.9898\n",
      "Epoch 30/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.0812 - accuracy: 0.9944\n",
      "Epoch 31/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.0688 - accuracy: 0.9955\n",
      "Epoch 32/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.0712 - accuracy: 0.9926\n",
      "Epoch 33/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.0579 - accuracy: 0.9986\n",
      "Epoch 34/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.0469 - accuracy: 0.9982\n",
      "Epoch 35/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.0461 - accuracy: 0.9974\n",
      "Epoch 36/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.0489 - accuracy: 0.9951\n",
      "Epoch 37/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.0314 - accuracy: 0.9993\n",
      "Epoch 38/50\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.0352 - accuracy: 0.9975\n",
      "Epoch 39/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.0379 - accuracy: 0.9983\n",
      "Epoch 40/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.0352 - accuracy: 0.9961\n",
      "Epoch 41/50\n",
      "143/143 [==============================] - 3s 23ms/step - loss: 0.0225 - accuracy: 0.9994\n",
      "Epoch 42/50\n",
      "143/143 [==============================] - 3s 22ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.0163 - accuracy: 0.9998\n",
      "Epoch 44/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.0158 - accuracy: 0.9999\n",
      "Epoch 45/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.0158 - accuracy: 0.9993\n",
      "Epoch 46/50\n",
      "143/143 [==============================] - 3s 19ms/step - loss: 0.0199 - accuracy: 0.9973\n",
      "Epoch 47/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.0243 - accuracy: 0.9957\n",
      "Epoch 48/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.0901 - accuracy: 0.9797\n",
      "Epoch 49/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.0569 - accuracy: 0.9869\n",
      "Epoch 50/50\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.0104 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_x, training_t, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 - 1s - loss: 0.0077 - accuracy: 1.0000\n",
      "Train accuracy: 1.0\n",
      "\n",
      "143/143 - 1s - loss: 9.3871 - accuracy: 0.0807\n",
      "Test accuracy: 0.08070175349712372\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "eval_model(training_x,training_t,testing_x,testing_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_73 (Conv2D)           (None, 14, 14, 14)        378       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 7, 7, 14)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 6, 6, 28)          1596      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 3, 3, 28)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 2, 2, 28)          3164      \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 28)                3164      \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 15)                435       \n",
      "=================================================================\n",
      "Total params: 8,737\n",
      "Trainable params: 8,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(input_size_gaf[0], 1, padding=\"same\", activation='relu', input_shape=input_size_gaf))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(input_size_gaf[0]*2, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(input_size_gaf[0]*2, (2, 2), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(input_size_gaf[0]*2, activation='relu'))\n",
    "model.add(layers.Dense(15))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tf.keras.backend.set_value(model.optimizer.learning_rate, 0.000025)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "66/66 [==============================] - 2s 13ms/step - loss: 9.2604 - accuracy: 0.0443\n",
      "Epoch 2/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 8.6670 - accuracy: 0.0431\n",
      "Epoch 3/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 8.4404 - accuracy: 0.0498\n",
      "Epoch 4/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 8.0389 - accuracy: 0.0520\n",
      "Epoch 5/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.9199 - accuracy: 0.0403\n",
      "Epoch 6/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 8.0404 - accuracy: 0.0430\n",
      "Epoch 7/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.6251 - accuracy: 0.0491\n",
      "Epoch 8/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 7.7641 - accuracy: 0.0516\n",
      "Epoch 9/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 7.6033 - accuracy: 0.0573\n",
      "Epoch 10/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.4199 - accuracy: 0.0601: 0s - loss: 7.3863 - accu\n",
      "Epoch 11/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 7.6812 - accuracy: 0.0577\n",
      "Epoch 12/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.2355 - accuracy: 0.0600\n",
      "Epoch 13/500\n",
      "66/66 [==============================] - 1s 7ms/step - loss: 7.2155 - accuracy: 0.0638\n",
      "Epoch 14/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.4391 - accuracy: 0.0637\n",
      "Epoch 15/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.1781 - accuracy: 0.0700\n",
      "Epoch 16/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 7.3319 - accuracy: 0.0592\n",
      "Epoch 17/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 6.8943 - accuracy: 0.0740\n",
      "Epoch 18/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 6.6804 - accuracy: 0.0757\n",
      "Epoch 19/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 7.1180 - accuracy: 0.0700\n",
      "Epoch 20/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 6.6744 - accuracy: 0.0693\n",
      "Epoch 21/500\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 6.4311 - accuracy: 0.0705\n",
      "Epoch 22/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 6.6971 - accuracy: 0.0851\n",
      "Epoch 23/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 6.5840 - accuracy: 0.0729\n",
      "Epoch 24/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.5168 - accuracy: 0.0784\n",
      "Epoch 25/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.7028 - accuracy: 0.0864\n",
      "Epoch 26/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6.3681 - accuracy: 0.0826\n",
      "Epoch 27/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.3850 - accuracy: 0.0841\n",
      "Epoch 28/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.3847 - accuracy: 0.0816\n",
      "Epoch 29/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.4182 - accuracy: 0.0816\n",
      "Epoch 30/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.5096 - accuracy: 0.0748\n",
      "Epoch 31/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.3566 - accuracy: 0.0778\n",
      "Epoch 32/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.4271 - accuracy: 0.0743\n",
      "Epoch 33/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 6.3966 - accuracy: 0.0783\n",
      "Epoch 34/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.1835 - accuracy: 0.0813\n",
      "Epoch 35/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.2913 - accuracy: 0.0772\n",
      "Epoch 36/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 6.2529 - accuracy: 0.0775\n",
      "Epoch 37/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 6.2328 - accuracy: 0.0838\n",
      "Epoch 38/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 6.3589 - accuracy: 0.0827\n",
      "Epoch 39/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6.0797 - accuracy: 0.0934\n",
      "Epoch 40/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.1649 - accuracy: 0.0819\n",
      "Epoch 41/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.3131 - accuracy: 0.0858\n",
      "Epoch 42/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.9752 - accuracy: 0.0882\n",
      "Epoch 43/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.9368 - accuracy: 0.0914\n",
      "Epoch 44/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.1905 - accuracy: 0.0982\n",
      "Epoch 45/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 6.0844 - accuracy: 0.1053\n",
      "Epoch 46/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 6.0928 - accuracy: 0.1012\n",
      "Epoch 47/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 6.2406 - accuracy: 0.0967\n",
      "Epoch 48/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.0671 - accuracy: 0.0899\n",
      "Epoch 49/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 6.0419 - accuracy: 0.1067\n",
      "Epoch 50/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.9512 - accuracy: 0.1035\n",
      "Epoch 51/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.1663 - accuracy: 0.0899\n",
      "Epoch 52/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 5.9965 - accuracy: 0.0865\n",
      "Epoch 53/500\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 5.9182 - accuracy: 0.1047\n",
      "Epoch 54/500\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 5.9729 - accuracy: 0.1002\n",
      "Epoch 55/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.9958 - accuracy: 0.0954\n",
      "Epoch 56/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.9865 - accuracy: 0.0888\n",
      "Epoch 57/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.8751 - accuracy: 0.1003\n",
      "Epoch 58/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6806 - accuracy: 0.1100\n",
      "Epoch 59/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.8258 - accuracy: 0.0979\n",
      "Epoch 60/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.9909 - accuracy: 0.1002\n",
      "Epoch 61/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.8960 - accuracy: 0.0969\n",
      "Epoch 62/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.7520 - accuracy: 0.0887\n",
      "Epoch 63/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 6.0439 - accuracy: 0.0928 0s - loss: 6.0957 - accura\n",
      "Epoch 64/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.9086 - accuracy: 0.0961\n",
      "Epoch 65/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.8748 - accuracy: 0.1050\n",
      "Epoch 66/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 5.6510 - accuracy: 0.1062\n",
      "Epoch 67/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.1104 - accuracy: 0.0972\n",
      "Epoch 68/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.9197 - accuracy: 0.0898\n",
      "Epoch 69/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.8786 - accuracy: 0.1016\n",
      "Epoch 70/500\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 5.6793 - accuracy: 0.0896\n",
      "Epoch 71/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.5807 - accuracy: 0.0899\n",
      "Epoch 72/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.7592 - accuracy: 0.0969\n",
      "Epoch 73/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.8630 - accuracy: 0.0931\n",
      "Epoch 74/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.5371 - accuracy: 0.0977\n",
      "Epoch 75/500\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 5.7155 - accuracy: 0.0874\n",
      "Epoch 76/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 5.5985 - accuracy: 0.0980\n",
      "Epoch 77/500\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 5.7366 - accuracy: 0.1032\n",
      "Epoch 78/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 5.6857 - accuracy: 0.0957\n",
      "Epoch 79/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.6296 - accuracy: 0.0890\n",
      "Epoch 80/500\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 5.8812 - accuracy: 0.0931\n",
      "Epoch 81/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.7258 - accuracy: 0.0981\n",
      "Epoch 82/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6688 - accuracy: 0.0883\n",
      "Epoch 83/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.5275 - accuracy: 0.1058\n",
      "Epoch 84/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.5095 - accuracy: 0.0915\n",
      "Epoch 85/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.8282 - accuracy: 0.0922\n",
      "Epoch 86/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.6663 - accuracy: 0.0953\n",
      "Epoch 87/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6399 - accuracy: 0.0955\n",
      "Epoch 88/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.5880 - accuracy: 0.0929\n",
      "Epoch 89/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.5008 - accuracy: 0.1008\n",
      "Epoch 90/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.6505 - accuracy: 0.0935\n",
      "Epoch 91/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.8884 - accuracy: 0.0926\n",
      "Epoch 92/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.4592 - accuracy: 0.0946\n",
      "Epoch 93/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.9007 - accuracy: 0.0932\n",
      "Epoch 94/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6034 - accuracy: 0.0941\n",
      "Epoch 95/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6890 - accuracy: 0.0978\n",
      "Epoch 96/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.8243 - accuracy: 0.0966\n",
      "Epoch 97/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.6275 - accuracy: 0.1003\n",
      "Epoch 98/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6951 - accuracy: 0.1061\n",
      "Epoch 99/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.9560 - accuracy: 0.0902\n",
      "Epoch 100/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7430 - accuracy: 0.0973\n",
      "Epoch 101/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7016 - accuracy: 0.0951\n",
      "Epoch 102/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.8108 - accuracy: 0.0956\n",
      "Epoch 103/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.7560 - accuracy: 0.1001\n",
      "Epoch 104/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.7793 - accuracy: 0.1109\n",
      "Epoch 105/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.7645 - accuracy: 0.1000\n",
      "Epoch 106/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.9168 - accuracy: 0.0902\n",
      "Epoch 107/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7389 - accuracy: 0.0933\n",
      "Epoch 108/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6234 - accuracy: 0.0970\n",
      "Epoch 109/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.6830 - accuracy: 0.1153\n",
      "Epoch 110/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.7082 - accuracy: 0.1074\n",
      "Epoch 111/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.5972 - accuracy: 0.1045\n",
      "Epoch 112/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6548 - accuracy: 0.1041\n",
      "Epoch 113/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.4633 - accuracy: 0.0962\n",
      "Epoch 114/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.7954 - accuracy: 0.1047\n",
      "Epoch 115/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6732 - accuracy: 0.1136\n",
      "Epoch 116/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7097 - accuracy: 0.1030\n",
      "Epoch 117/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.5618 - accuracy: 0.1077\n",
      "Epoch 118/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.5468 - accuracy: 0.1054\n",
      "Epoch 119/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.4500 - accuracy: 0.1029\n",
      "Epoch 120/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.5371 - accuracy: 0.0956\n",
      "Epoch 121/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6206 - accuracy: 0.0958\n",
      "Epoch 122/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 5.7488 - accuracy: 0.0906\n",
      "Epoch 123/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.8536 - accuracy: 0.1061\n",
      "Epoch 124/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7124 - accuracy: 0.0873\n",
      "Epoch 125/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6345 - accuracy: 0.0993\n",
      "Epoch 126/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.8103 - accuracy: 0.1127\n",
      "Epoch 127/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.5317 - accuracy: 0.1027\n",
      "Epoch 128/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7248 - accuracy: 0.0972\n",
      "Epoch 129/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6475 - accuracy: 0.0869\n",
      "Epoch 130/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6106 - accuracy: 0.1081\n",
      "Epoch 131/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7107 - accuracy: 0.1042\n",
      "Epoch 132/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.4717 - accuracy: 0.1030\n",
      "Epoch 133/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6228 - accuracy: 0.1136\n",
      "Epoch 134/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.4383 - accuracy: 0.1056\n",
      "Epoch 135/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.5594 - accuracy: 0.1096\n",
      "Epoch 136/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.6332 - accuracy: 0.1093\n",
      "Epoch 137/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.7302 - accuracy: 0.1197\n",
      "Epoch 138/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6611 - accuracy: 0.1109\n",
      "Epoch 139/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6107 - accuracy: 0.1116\n",
      "Epoch 140/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.3214 - accuracy: 0.1131: 0s - loss: 4.9822 - accura\n",
      "Epoch 141/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.5924 - accuracy: 0.1127: 0s - loss: 5.5917 - accuracy: 0.\n",
      "Epoch 142/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.5983 - accuracy: 0.1086\n",
      "Epoch 143/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.4770 - accuracy: 0.1162\n",
      "Epoch 144/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.4386 - accuracy: 0.1075\n",
      "Epoch 145/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7886 - accuracy: 0.1025\n",
      "Epoch 146/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.4832 - accuracy: 0.1216\n",
      "Epoch 147/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6628 - accuracy: 0.1002\n",
      "Epoch 148/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.5429 - accuracy: 0.1010\n",
      "Epoch 149/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6056 - accuracy: 0.1078\n",
      "Epoch 150/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.5832 - accuracy: 0.1240\n",
      "Epoch 151/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.5028 - accuracy: 0.1082\n",
      "Epoch 152/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7526 - accuracy: 0.1097\n",
      "Epoch 153/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.5695 - accuracy: 0.1195\n",
      "Epoch 154/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.7270 - accuracy: 0.1071\n",
      "Epoch 155/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.6225 - accuracy: 0.1085\n",
      "Epoch 156/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.3792 - accuracy: 0.1209\n",
      "Epoch 157/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.4805 - accuracy: 0.1101\n",
      "Epoch 158/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.4211 - accuracy: 0.1080\n",
      "Epoch 159/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6631 - accuracy: 0.1186\n",
      "Epoch 160/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.6209 - accuracy: 0.1069\n",
      "Epoch 161/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.4473 - accuracy: 0.1097\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 5.4794 - accuracy: 0.1136\n",
      "Epoch 163/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.4319 - accuracy: 0.1037\n",
      "Epoch 164/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.4944 - accuracy: 0.1155\n",
      "Epoch 165/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.4612 - accuracy: 0.1050\n",
      "Epoch 166/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.3099 - accuracy: 0.1114\n",
      "Epoch 167/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.2894 - accuracy: 0.1130\n",
      "Epoch 168/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.4448 - accuracy: 0.1080\n",
      "Epoch 169/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.5000 - accuracy: 0.1065\n",
      "Epoch 170/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.5127 - accuracy: 0.1111\n",
      "Epoch 171/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.3544 - accuracy: 0.1165\n",
      "Epoch 172/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6445 - accuracy: 0.1045\n",
      "Epoch 173/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.3293 - accuracy: 0.1089\n",
      "Epoch 174/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.3238 - accuracy: 0.1124\n",
      "Epoch 175/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.6078 - accuracy: 0.0991\n",
      "Epoch 176/500\n",
      "66/66 [==============================] - 0s 8ms/step - loss: 5.3113 - accuracy: 0.0990\n",
      "Epoch 177/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.2980 - accuracy: 0.1101\n",
      "Epoch 178/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.6127 - accuracy: 0.1045\n",
      "Epoch 179/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.3166 - accuracy: 0.1100\n",
      "Epoch 180/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.3378 - accuracy: 0.1039\n",
      "Epoch 181/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.4807 - accuracy: 0.1123\n",
      "Epoch 182/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.3582 - accuracy: 0.1057\n",
      "Epoch 183/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.4994 - accuracy: 0.1099\n",
      "Epoch 184/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.3266 - accuracy: 0.1149\n",
      "Epoch 185/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.3363 - accuracy: 0.1064\n",
      "Epoch 186/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.2896 - accuracy: 0.0994\n",
      "Epoch 187/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.2623 - accuracy: 0.1158\n",
      "Epoch 188/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.1130 - accuracy: 0.0982\n",
      "Epoch 189/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.1312 - accuracy: 0.1104\n",
      "Epoch 190/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.0535 - accuracy: 0.1094\n",
      "Epoch 191/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.2792 - accuracy: 0.1048\n",
      "Epoch 192/500\n",
      "66/66 [==============================] - 0s 8ms/step - loss: 5.3038 - accuracy: 0.1173\n",
      "Epoch 193/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.3079 - accuracy: 0.1138\n",
      "Epoch 194/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.3155 - accuracy: 0.1062\n",
      "Epoch 195/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.2566 - accuracy: 0.1057\n",
      "Epoch 196/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.3511 - accuracy: 0.1116\n",
      "Epoch 197/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.3068 - accuracy: 0.1017\n",
      "Epoch 198/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.1346 - accuracy: 0.1045\n",
      "Epoch 199/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.1154 - accuracy: 0.1180\n",
      "Epoch 200/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.3488 - accuracy: 0.0992\n",
      "Epoch 201/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.0785 - accuracy: 0.1177\n",
      "Epoch 202/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.1579 - accuracy: 0.1217\n",
      "Epoch 203/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.2019 - accuracy: 0.1196\n",
      "Epoch 204/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.1487 - accuracy: 0.1281\n",
      "Epoch 205/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.1361 - accuracy: 0.1034\n",
      "Epoch 206/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9633 - accuracy: 0.1060\n",
      "Epoch 207/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.3022 - accuracy: 0.1209\n",
      "Epoch 208/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.2480 - accuracy: 0.1244\n",
      "Epoch 209/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0557 - accuracy: 0.1126\n",
      "Epoch 210/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9018 - accuracy: 0.1094\n",
      "Epoch 211/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.1033 - accuracy: 0.1118\n",
      "Epoch 212/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9799 - accuracy: 0.1253\n",
      "Epoch 213/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0380 - accuracy: 0.1157\n",
      "Epoch 214/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0667 - accuracy: 0.1194\n",
      "Epoch 215/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0065 - accuracy: 0.1199\n",
      "Epoch 216/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9527 - accuracy: 0.1241\n",
      "Epoch 217/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0205 - accuracy: 0.1225\n",
      "Epoch 218/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7209 - accuracy: 0.1241\n",
      "Epoch 219/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0331 - accuracy: 0.1121\n",
      "Epoch 220/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9367 - accuracy: 0.1301\n",
      "Epoch 221/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.0781 - accuracy: 0.1147\n",
      "Epoch 222/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.7315 - accuracy: 0.1192\n",
      "Epoch 223/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.2224 - accuracy: 0.1235\n",
      "Epoch 224/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.8536 - accuracy: 0.1329\n",
      "Epoch 225/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.0331 - accuracy: 0.1179\n",
      "Epoch 226/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.0489 - accuracy: 0.1243\n",
      "Epoch 227/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.1828 - accuracy: 0.1190\n",
      "Epoch 228/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8018 - accuracy: 0.1244\n",
      "Epoch 229/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0562 - accuracy: 0.1300\n",
      "Epoch 230/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7943 - accuracy: 0.1201\n",
      "Epoch 231/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0226 - accuracy: 0.1331\n",
      "Epoch 232/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9297 - accuracy: 0.1223\n",
      "Epoch 233/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0849 - accuracy: 0.1114\n",
      "Epoch 234/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7309 - accuracy: 0.1234\n",
      "Epoch 235/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.9585 - accuracy: 0.1183\n",
      "Epoch 236/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.8826 - accuracy: 0.1239\n",
      "Epoch 237/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8289 - accuracy: 0.1353\n",
      "Epoch 238/500\n",
      "66/66 [==============================] - ETA: 0s - loss: 4.9134 - accuracy: 0.13 - 0s 5ms/step - loss: 4.9112 - accuracy: 0.1333\n",
      "Epoch 239/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.9471 - accuracy: 0.1244\n",
      "Epoch 240/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.9239 - accuracy: 0.1231\n",
      "Epoch 241/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.0727 - accuracy: 0.1232\n",
      "Epoch 242/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.9032 - accuracy: 0.1275\n",
      "Epoch 243/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6527 - accuracy: 0.1403\n",
      "Epoch 244/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.8004 - accuracy: 0.1372\n",
      "Epoch 245/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.9550 - accuracy: 0.1300\n",
      "Epoch 246/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8488 - accuracy: 0.1339\n",
      "Epoch 247/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8655 - accuracy: 0.1288\n",
      "Epoch 248/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9053 - accuracy: 0.1359\n",
      "Epoch 249/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9417 - accuracy: 0.1335\n",
      "Epoch 250/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8744 - accuracy: 0.1314\n",
      "Epoch 251/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8140 - accuracy: 0.1247\n",
      "Epoch 252/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7121 - accuracy: 0.1361\n",
      "Epoch 253/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.9330 - accuracy: 0.1329\n",
      "Epoch 254/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.7766 - accuracy: 0.1411\n",
      "Epoch 255/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.7570 - accuracy: 0.1331\n",
      "Epoch 256/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.9044 - accuracy: 0.1439\n",
      "Epoch 257/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9456 - accuracy: 0.1386\n",
      "Epoch 258/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6576 - accuracy: 0.1372\n",
      "Epoch 259/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 5.0257 - accuracy: 0.1393\n",
      "Epoch 260/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8773 - accuracy: 0.1445\n",
      "Epoch 261/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9689 - accuracy: 0.1428\n",
      "Epoch 262/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8805 - accuracy: 0.1377\n",
      "Epoch 263/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8377 - accuracy: 0.1482\n",
      "Epoch 264/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9453 - accuracy: 0.1418\n",
      "Epoch 265/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8185 - accuracy: 0.1264\n",
      "Epoch 266/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.8085 - accuracy: 0.1424\n",
      "Epoch 267/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.7533 - accuracy: 0.1302\n",
      "Epoch 268/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8867 - accuracy: 0.1528\n",
      "Epoch 269/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8370 - accuracy: 0.1384\n",
      "Epoch 270/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.8237 - accuracy: 0.1294\n",
      "Epoch 271/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6340 - accuracy: 0.1383\n",
      "Epoch 272/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.9037 - accuracy: 0.1441\n",
      "Epoch 273/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.9380 - accuracy: 0.1462\n",
      "Epoch 274/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8167 - accuracy: 0.1449\n",
      "Epoch 275/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8444 - accuracy: 0.1475\n",
      "Epoch 276/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7628 - accuracy: 0.1399\n",
      "Epoch 277/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.7268 - accuracy: 0.1372\n",
      "Epoch 278/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.0768 - accuracy: 0.1333\n",
      "Epoch 279/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.7363 - accuracy: 0.1375\n",
      "Epoch 280/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.8577 - accuracy: 0.1445\n",
      "Epoch 281/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.6981 - accuracy: 0.1353\n",
      "Epoch 282/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.7681 - accuracy: 0.1336\n",
      "Epoch 283/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.7465 - accuracy: 0.1383\n",
      "Epoch 284/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.7636 - accuracy: 0.1497\n",
      "Epoch 285/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.7720 - accuracy: 0.1311\n",
      "Epoch 286/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7863 - accuracy: 0.1412\n",
      "Epoch 287/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.0157 - accuracy: 0.1273\n",
      "Epoch 288/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7149 - accuracy: 0.1424\n",
      "Epoch 289/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.6686 - accuracy: 0.1393\n",
      "Epoch 290/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.6258 - accuracy: 0.1443\n",
      "Epoch 291/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7507 - accuracy: 0.1228\n",
      "Epoch 292/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.6401 - accuracy: 0.1442\n",
      "Epoch 293/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.6808 - accuracy: 0.1483\n",
      "Epoch 294/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.7057 - accuracy: 0.1315\n",
      "Epoch 295/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.6923 - accuracy: 0.1442\n",
      "Epoch 296/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7274 - accuracy: 0.1317\n",
      "Epoch 297/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6471 - accuracy: 0.1435\n",
      "Epoch 298/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7394 - accuracy: 0.1363\n",
      "Epoch 299/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6097 - accuracy: 0.1351\n",
      "Epoch 300/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7389 - accuracy: 0.1426\n",
      "Epoch 301/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7383 - accuracy: 0.1466\n",
      "Epoch 302/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.5585 - accuracy: 0.1550\n",
      "Epoch 303/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.7198 - accuracy: 0.1404\n",
      "Epoch 304/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.4572 - accuracy: 0.1472\n",
      "Epoch 305/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5947 - accuracy: 0.1577\n",
      "Epoch 306/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.6152 - accuracy: 0.1417\n",
      "Epoch 307/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.5362 - accuracy: 0.1481\n",
      "Epoch 308/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6689 - accuracy: 0.1447\n",
      "Epoch 309/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.5762 - accuracy: 0.1477\n",
      "Epoch 310/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.8088 - accuracy: 0.1379\n",
      "Epoch 311/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.6906 - accuracy: 0.1478\n",
      "Epoch 312/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6631 - accuracy: 0.1337\n",
      "Epoch 313/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5960 - accuracy: 0.1518\n",
      "Epoch 314/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8051 - accuracy: 0.1475\n",
      "Epoch 315/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5545 - accuracy: 0.1506\n",
      "Epoch 316/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.5930 - accuracy: 0.1403\n",
      "Epoch 317/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5275 - accuracy: 0.1453\n",
      "Epoch 318/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.6174 - accuracy: 0.1533\n",
      "Epoch 319/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.6832 - accuracy: 0.1417\n",
      "Epoch 320/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5296 - accuracy: 0.1536\n",
      "Epoch 321/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.5430 - accuracy: 0.1468\n",
      "Epoch 322/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.4817 - accuracy: 0.1552\n",
      "Epoch 323/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5892 - accuracy: 0.1490\n",
      "Epoch 324/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.6363 - accuracy: 0.1329\n",
      "Epoch 325/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6934 - accuracy: 0.1444\n",
      "Epoch 326/500\n",
      "66/66 [==============================] - 0s 8ms/step - loss: 4.6434 - accuracy: 0.1565\n",
      "Epoch 327/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.6055 - accuracy: 0.1497\n",
      "Epoch 328/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.7108 - accuracy: 0.1457\n",
      "Epoch 329/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.6354 - accuracy: 0.1565\n",
      "Epoch 330/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.4456 - accuracy: 0.1661\n",
      "Epoch 331/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6258 - accuracy: 0.1532\n",
      "Epoch 332/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5537 - accuracy: 0.1637\n",
      "Epoch 333/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3818 - accuracy: 0.1596\n",
      "Epoch 334/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6260 - accuracy: 0.1536\n",
      "Epoch 335/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.5933 - accuracy: 0.1371\n",
      "Epoch 336/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2556 - accuracy: 0.1589\n",
      "Epoch 337/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.7461 - accuracy: 0.1487\n",
      "Epoch 338/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.5858 - accuracy: 0.1600\n",
      "Epoch 339/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6487 - accuracy: 0.1530\n",
      "Epoch 340/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3478 - accuracy: 0.1649\n",
      "Epoch 341/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5105 - accuracy: 0.1513\n",
      "Epoch 342/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.4572 - accuracy: 0.1669\n",
      "Epoch 343/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5340 - accuracy: 0.1479\n",
      "Epoch 344/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.5162 - accuracy: 0.1469\n",
      "Epoch 345/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6199 - accuracy: 0.1562\n",
      "Epoch 346/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5546 - accuracy: 0.1475\n",
      "Epoch 347/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.4482 - accuracy: 0.1599\n",
      "Epoch 348/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5758 - accuracy: 0.1422\n",
      "Epoch 349/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.3540 - accuracy: 0.1536\n",
      "Epoch 350/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.8338 - accuracy: 0.1488\n",
      "Epoch 351/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.4226 - accuracy: 0.1496\n",
      "Epoch 352/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.4109 - accuracy: 0.1591\n",
      "Epoch 353/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3674 - accuracy: 0.1663\n",
      "Epoch 354/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.5272 - accuracy: 0.1577\n",
      "Epoch 355/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.5894 - accuracy: 0.1439\n",
      "Epoch 356/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.3302 - accuracy: 0.1505\n",
      "Epoch 357/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.4009 - accuracy: 0.1528\n",
      "Epoch 358/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.4876 - accuracy: 0.1600\n",
      "Epoch 359/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.4435 - accuracy: 0.1562\n",
      "Epoch 360/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6251 - accuracy: 0.1555\n",
      "Epoch 361/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.4409 - accuracy: 0.1662\n",
      "Epoch 362/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.6347 - accuracy: 0.1427\n",
      "Epoch 363/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5292 - accuracy: 0.1421\n",
      "Epoch 364/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.4033 - accuracy: 0.1596\n",
      "Epoch 365/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.5951 - accuracy: 0.1552\n",
      "Epoch 366/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.4526 - accuracy: 0.1508\n",
      "Epoch 367/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3634 - accuracy: 0.1443\n",
      "Epoch 368/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.5426 - accuracy: 0.1395\n",
      "Epoch 369/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.6056 - accuracy: 0.1630\n",
      "Epoch 370/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.4664 - accuracy: 0.1734\n",
      "Epoch 371/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3610 - accuracy: 0.1669\n",
      "Epoch 372/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.3625 - accuracy: 0.1482\n",
      "Epoch 373/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3838 - accuracy: 0.1568\n",
      "Epoch 374/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.4697 - accuracy: 0.1673\n",
      "Epoch 375/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2820 - accuracy: 0.1669\n",
      "Epoch 376/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3243 - accuracy: 0.1578\n",
      "Epoch 377/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.4632 - accuracy: 0.1631\n",
      "Epoch 378/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5912 - accuracy: 0.1483\n",
      "Epoch 379/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2214 - accuracy: 0.1527\n",
      "Epoch 380/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.3339 - accuracy: 0.1632\n",
      "Epoch 381/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.4653 - accuracy: 0.1584\n",
      "Epoch 382/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.2110 - accuracy: 0.1756\n",
      "Epoch 383/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3829 - accuracy: 0.1646\n",
      "Epoch 384/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.4752 - accuracy: 0.1744\n",
      "Epoch 385/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.5113 - accuracy: 0.1538\n",
      "Epoch 386/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.4056 - accuracy: 0.1502\n",
      "Epoch 387/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.4923 - accuracy: 0.1469\n",
      "Epoch 388/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.3721 - accuracy: 0.1584: 0s - loss: 4.2676 - \n",
      "Epoch 389/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.2630 - accuracy: 0.1629\n",
      "Epoch 390/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.3429 - accuracy: 0.1537\n",
      "Epoch 391/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.3581 - accuracy: 0.1700\n",
      "Epoch 392/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3681 - accuracy: 0.1631\n",
      "Epoch 393/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.1101 - accuracy: 0.1527\n",
      "Epoch 394/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.2419 - accuracy: 0.1675\n",
      "Epoch 395/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.2659 - accuracy: 0.1649\n",
      "Epoch 396/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2139 - accuracy: 0.1589\n",
      "Epoch 397/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.3338 - accuracy: 0.1600\n",
      "Epoch 398/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3823 - accuracy: 0.1476\n",
      "Epoch 399/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2933 - accuracy: 0.1746\n",
      "Epoch 400/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1901 - accuracy: 0.1569\n",
      "Epoch 401/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2354 - accuracy: 0.1627\n",
      "Epoch 402/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2057 - accuracy: 0.1837\n",
      "Epoch 403/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.1362 - accuracy: 0.1755\n",
      "Epoch 404/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 6ms/step - loss: 4.3822 - accuracy: 0.1592\n",
      "Epoch 405/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2545 - accuracy: 0.1556\n",
      "Epoch 406/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3251 - accuracy: 0.1671\n",
      "Epoch 407/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.2478 - accuracy: 0.1458\n",
      "Epoch 408/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.2497 - accuracy: 0.1639\n",
      "Epoch 409/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.3085 - accuracy: 0.1721\n",
      "Epoch 410/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.1387 - accuracy: 0.1723\n",
      "Epoch 411/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.3164 - accuracy: 0.1712\n",
      "Epoch 412/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.2149 - accuracy: 0.1696\n",
      "Epoch 413/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.3016 - accuracy: 0.1651\n",
      "Epoch 414/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2888 - accuracy: 0.1661\n",
      "Epoch 415/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.0740 - accuracy: 0.1704\n",
      "Epoch 416/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.1035 - accuracy: 0.1705\n",
      "Epoch 417/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.2306 - accuracy: 0.1642\n",
      "Epoch 418/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.3547 - accuracy: 0.1666\n",
      "Epoch 419/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.3205 - accuracy: 0.1596\n",
      "Epoch 420/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1833 - accuracy: 0.1695\n",
      "Epoch 421/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.4496 - accuracy: 0.1628\n",
      "Epoch 422/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.1022 - accuracy: 0.1733\n",
      "Epoch 423/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2792 - accuracy: 0.1695\n",
      "Epoch 424/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3935 - accuracy: 0.1720\n",
      "Epoch 425/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.1195 - accuracy: 0.1703\n",
      "Epoch 426/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.0647 - accuracy: 0.1740\n",
      "Epoch 427/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2029 - accuracy: 0.1678\n",
      "Epoch 428/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.3815 - accuracy: 0.1583\n",
      "Epoch 429/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2082 - accuracy: 0.1743\n",
      "Epoch 430/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1891 - accuracy: 0.1638\n",
      "Epoch 431/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.1096 - accuracy: 0.1774\n",
      "Epoch 432/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2458 - accuracy: 0.1759\n",
      "Epoch 433/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1713 - accuracy: 0.1721\n",
      "Epoch 434/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1922 - accuracy: 0.1855\n",
      "Epoch 435/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1533 - accuracy: 0.1831\n",
      "Epoch 436/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.1854 - accuracy: 0.1661\n",
      "Epoch 437/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2691 - accuracy: 0.1728\n",
      "Epoch 438/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.0775 - accuracy: 0.1717\n",
      "Epoch 439/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2436 - accuracy: 0.1794\n",
      "Epoch 440/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.2301 - accuracy: 0.1829\n",
      "Epoch 441/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.1803 - accuracy: 0.1742\n",
      "Epoch 442/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.2863 - accuracy: 0.1777\n",
      "Epoch 443/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.1152 - accuracy: 0.1813\n",
      "Epoch 444/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.3076 - accuracy: 0.1775\n",
      "Epoch 445/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2985 - accuracy: 0.1709\n",
      "Epoch 446/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.0296 - accuracy: 0.1667\n",
      "Epoch 447/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.1493 - accuracy: 0.1819\n",
      "Epoch 448/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.2495 - accuracy: 0.1600\n",
      "Epoch 449/500\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 4.2336 - accuracy: 0.1650\n",
      "Epoch 450/500\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.1908 - accuracy: 0.1687\n",
      "Epoch 451/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.2147 - accuracy: 0.1616\n",
      "Epoch 452/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.3414 - accuracy: 0.1620\n",
      "Epoch 453/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 3.9825 - accuracy: 0.1756\n",
      "Epoch 454/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 4.2554 - accuracy: 0.1702\n",
      "Epoch 455/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.3090 - accuracy: 0.1714\n",
      "Epoch 456/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.2750 - accuracy: 0.1892\n",
      "Epoch 457/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 4.2287 - accuracy: 0.1726\n",
      "Epoch 458/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1572 - accuracy: 0.1679\n",
      "Epoch 459/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1549 - accuracy: 0.1725\n",
      "Epoch 460/500\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.1356 - accuracy: 0.1777\n",
      "Epoch 461/500\n",
      "66/66 [==============================] - 1s 7ms/step - loss: 4.0004 - accuracy: 0.1858\n",
      "Epoch 462/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1055 - accuracy: 0.1778\n",
      "Epoch 463/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 3.9770 - accuracy: 0.1711\n",
      "Epoch 464/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.1885 - accuracy: 0.1898\n",
      "Epoch 465/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.0269 - accuracy: 0.1852\n",
      "Epoch 466/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2184 - accuracy: 0.1828\n",
      "Epoch 467/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.0954 - accuracy: 0.1763\n",
      "Epoch 468/500\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 4.1856 - accuracy: 0.1720\n",
      "Epoch 469/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.1184 - accuracy: 0.1708\n",
      "Epoch 470/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.0561 - accuracy: 0.1793\n",
      "Epoch 471/500\n",
      "66/66 [==============================] - 1s 7ms/step - loss: 4.1933 - accuracy: 0.1829\n",
      "Epoch 472/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.2731 - accuracy: 0.1831\n",
      "Epoch 473/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 4.1053 - accuracy: 0.1767\n",
      "Epoch 474/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2828 - accuracy: 0.1736\n",
      "Epoch 475/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.2933 - accuracy: 0.1619\n",
      "Epoch 476/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.1216 - accuracy: 0.1704\n",
      "Epoch 477/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2181 - accuracy: 0.1660\n",
      "Epoch 478/500\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 4.0941 - accuracy: 0.1900\n",
      "Epoch 479/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.1787 - accuracy: 0.1800\n",
      "Epoch 480/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.1783 - accuracy: 0.1604\n",
      "Epoch 481/500\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 4.1826 - accuracy: 0.1745\n",
      "Epoch 482/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.2241 - accuracy: 0.1870\n",
      "Epoch 483/500\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.9720 - accuracy: 0.1874\n",
      "Epoch 484/500\n",
      "66/66 [==============================] - 1s 7ms/step - loss: 4.2563 - accuracy: 0.1793\n",
      "Epoch 485/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2718 - accuracy: 0.1664\n",
      "Epoch 486/500\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 4.0000 - accuracy: 0.1813\n",
      "Epoch 487/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2124 - accuracy: 0.1849\n",
      "Epoch 488/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.0793 - accuracy: 0.1858\n",
      "Epoch 489/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 3.9736 - accuracy: 0.1900\n",
      "Epoch 490/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.1269 - accuracy: 0.1809\n",
      "Epoch 491/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 3.9030 - accuracy: 0.1940\n",
      "Epoch 492/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.0658 - accuracy: 0.1914\n",
      "Epoch 493/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2049 - accuracy: 0.1846\n",
      "Epoch 494/500\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4.2443 - accuracy: 0.1830\n",
      "Epoch 495/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.0822 - accuracy: 0.1922\n",
      "Epoch 496/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.2144 - accuracy: 0.1811\n",
      "Epoch 497/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.0218 - accuracy: 0.1827\n",
      "Epoch 498/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.0562 - accuracy: 0.1841\n",
      "Epoch 499/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.1210 - accuracy: 0.1748\n",
      "Epoch 500/500\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.2287 - accuracy: 0.1772\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(testing_x_gaf, testing_t, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f81bba1f610>]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 - 0s - loss: 4.1558 - accuracy: 0.1824\n",
      "Train accuracy: 0.18238095939159393\n",
      "\n",
      "66/66 - 0s - loss: 7.4227 - accuracy: 0.0924\n",
      "Test accuracy: 0.09238095581531525\n"
     ]
    }
   ],
   "source": [
    "eval_model(testing_x_gaf,testing_t,training_x_gaf,training_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06798245614035088\n"
     ]
    }
   ],
   "source": [
    "#KMeans with DTW distance\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "model = TimeSeriesKMeans(n_clusters=10, metric=\"dtw\", max_iter=10)\n",
    "model.fit(training_x,training_t)\n",
    "\n",
    "preds = model.predict(testing_x) == testing_t\n",
    "sum = 0\n",
    "for el in preds:\n",
    "    if el == True:\n",
    "        sum += 1\n",
    "print(\"Accuracy:\",sum/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
